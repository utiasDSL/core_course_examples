{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b43ac0",
   "metadata": {},
   "source": [
    "\n",
    "### **Chapter 3: Optimization Fundamentals**\n",
    "\n",
    "\n",
    "In this chapter, we introduce optimization problems with and without constraints. First, we present unconstrained optimization problems and introduce several commonly used solvers, as well as their implementations in code. These methods will be tested across a variety of examples to illustrate their respective performance. Subsequently, we extend the discussion to constrained optimization problems. Utilizing CasADi’s symbolic framework, we store symbolic expressions and leverage its built-in solvers (e.g., qpOASES) to solve the problems and visualize the results. The theoretical foundations and implementation techniques introduced in this chapter will serve as the basis for subsequent chapters on iterative LQR and Model Predictive Control (MPC).\n",
    "\n",
    "All the contents are summarized in the table below.  \n",
    "\n",
    "<table border=\"1\" style=\"border-collapse: collapse; text-align: center;\">\n",
    "  <!-- Title Row -->\n",
    "  <tr>\n",
    "    <th colspan=\"2\" style=\"text-align:center\">Content of Chapter 3 Exercise</th>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 1 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"3\">Unconstrained Optimization</td>\n",
    "    <td>Example 1.1: Manual Unconstrained Optimization Solver Implementation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 1.2~1.5: Using Implemented Solvers</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 1.6: Using Built-in Solvers</td>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 2 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"6\">Constrained Optimization</td>\n",
    "    <td>Example 2.1: Configuring Built-in Quadratic Programming Solvers</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 2.2: Solving QPs with Built-in Solvers</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 3.1: Manual Sequential QP Solver Implementation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 3.2: Using Implemented SQP Solver for Nonlinear Programming</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 3.3: Configuring Built-in SQP Solvers for NLP</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Example 3.4: Using Built-in SQP Solver for NLP</td>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "First, we need to import relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a30bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import casadi as ca\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df27691",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### **Problem Definition:**\n",
    "\n",
    "A generic optimization problem has the following form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{x}} \\quad & f(\\boldsymbol{x}) \\\\\\\\\n",
    "\\text{subject to} \\quad & h_i(\\boldsymbol{x}) = 0, \\quad \\forall i \\in \\{1, 2, \\dots, N\\}, \\\\\\\\\n",
    "& g_j(\\boldsymbol{x}) \\leq 0, \\quad \\forall j \\in \\{1, 2, \\dots, M\\},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $ \\boldsymbol{x} \\in \\mathbb{R}^n $ is the **optimization variable** of the problem, $ f : \\mathbb{R}^n \\mapsto \\mathbb{R} $ is the **objective function**, and $ h_i : \\mathbb{R}^n \\mapsto \\mathbb{R} $ and $ g_j : \\mathbb{R}^n \\mapsto \\mathbb{R} $ are the *equality* and **inequality constraint functions**, respectively. The objective function and the constraint functions can be general nonlinear functions. In this chapter, we generally assume that $ f $, $ h_i $, and $ g_j $ are differentiable functions.\n",
    "\n",
    "##### **Subclasses of optimization problems:**\n",
    "\n",
    "   1\\) **Unconstrained Optimization:**  A general optimization problem without any constraints is called an unconstrained optimization problem. In this case, the goal is to find a minimizer of the objective function without being restricted by any equality or inequality conditions.\n",
    "\n",
    "   2\\) **Linear Programming (LP):** An optimization problem is called a linear program if both the objective function and all the constraint functions are linear. Specifically, the objective is a linear function of the decision variables, and the feasible set is defined by linear equality and inequality constraints.\n",
    "\n",
    "   3\\) **Quadratic Programming (QP):** An optimization problem is called a quadratic program if the objective function is quadratic and the constraints are linear. That is, the objective function includes a quadratic term, while the equality and inequality constraints are affine functions of the decision variables.\n",
    "\n",
    "   4\\) **Nonlinear Programming (NLP):** A general optimization problem with at least one nonlinear function, either in the objective function, the inequality constraints, or the equality constraints, is called a nonlinear program. In a nonlinear program, the functions involved can be nonlinear, and solving such problems typically requires iterative numerical methods.\n",
    "\n",
    "   5\\) **Convex Programming:** An optimization problem with convex objective function and convex constraint functions. The important property of convex optimization problems is that every local minimum is also a global minimum. LPs and QPs are a special case of convex optimization problems. If any part of the problem is not convex, the problem is refered to as non-convex programming. \n",
    "\n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087f019",
   "metadata": {},
   "source": [
    "\n",
    "### **Part (a): Unconstrained Optimization**\n",
    "\n",
    "In this section, we introduce methods for solving unconstrained optimization problems. We begin by defining several common objective functions as testbeds for solvers. Afterwards we implement these solvers and evaluate their performance on the test problems and summarize the characteristics of different optimization methods.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6223f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### **Objective Functions:**\n",
    "\n",
    "As discussed above, unconstrained optimization primarily follows the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{x}} \\quad & f(\\boldsymbol{x}) \\,,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the objective function is typically selected from several standard forms. In the exercises of this chapter, we primarily use the following three objective functions as test cases:\n",
    "\n",
    "1) **Quadratic Function:** A simple convex function used as a basic test case for optimization algorithms: \n",
    "\n",
    "$$\n",
    "f(\\boldsymbol{x}) = \\left(\\frac{x_0}{2}\\right)^2 + x_1^2, \\quad \\boldsymbol{x}^* = [0, 0] \\,.\n",
    "$$\n",
    "\n",
    "2) **Rosenbrock Function:** A non-convex function used to test the performance of optimization algorithms, characterized by a narrow, curved valley leading to the global minimum:\n",
    "\n",
    "$$\n",
    "f(\\boldsymbol{x}) = (1 - x_0)^2 + 100 (x_1 - x_0^2)^2, \\quad \\boldsymbol{x}^* = [1, 1] \\,.\n",
    "$$\n",
    "\n",
    "3) **Rastrigin Function:** A highly multimodal function used to test the ability of algorithms to escape local minima, combining a quadratic term with a cosine modulation:\n",
    "\n",
    "$$\n",
    "f(\\boldsymbol{x}) = 20 + \\left( x_0^2 - 10 \\cos(2\\pi x_0) \\right) + \\left( x_1^2 - 10 \\cos(2\\pi x_1) \\right), \\quad \\boldsymbol{x}^* = [0, 0] \\,.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def quadratic(x):\n",
    "    return 1/2*(x[0]**2/4 + x[1]**2)\n",
    "\n",
    "quadratic_minimum = np.array([0.0, 0.0])\n",
    "\n",
    "def rosenbrock(x):\n",
    "    return (1 - x[0])**2 + 100*(x[1] - x[0]**2)**2\n",
    "\n",
    "rosenbrock_minimum = np.array([1.0, 1.0])\n",
    "\n",
    "def rastrigin_setup(pkg):\n",
    "    def rastrigin(x):\n",
    "        return 20 + (x[0]**2 - 10*pkg.cos(2*np.pi*x[0])) + (x[1]**2 - 10*pkg.cos(2*np.pi*x[1]))\n",
    "    return rastrigin\n",
    "\n",
    "rastrigin_minimum = np.array([0.0, 0.0])\n",
    "\n",
    "def plot_function(func, x_range, y_range):\n",
    "    x = np.linspace(x_range[0], x_range[1], 100)\n",
    "    y = np.linspace(y_range[0], y_range[1], 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = func(np.array([X, Y]))\n",
    "    return X, Y, Z\n",
    "\n",
    "functions = [quadratic, rosenbrock, rastrigin_setup(np)]\n",
    "minima = [quadratic_minimum, rosenbrock_minimum, rastrigin_minimum]\n",
    "\n",
    "# Create 3D plots for each function\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Define appropriate ranges for each function\n",
    "ranges = [\n",
    "    [(-4.5, 4.5), (-4.5, 4.5)],       # Quadratic\n",
    "    [(-2, 2), (-1, 3)],               # Rosenbrock\n",
    "    [(-5.12, 5.12), (-5.12, 5.12)]    # Rastrigin\n",
    "]\n",
    "\n",
    "titles = [\"Quadratic Function\", \"Rosenbrock Function\", \"Rastrigin Function\"]\n",
    "\n",
    "for i, (func, (x_range, y_range), title, minimum) in enumerate(zip(functions, ranges, titles, minima)):\n",
    "    ax = fig.add_subplot(1, 3, i+1, projection='3d')\n",
    "    X, Y, Z = plot_function(func, x_range, y_range)\n",
    "    \n",
    "    # Plot the global minimum as a red dashed line\n",
    "    min_val = np.min(Z) - 0.1 * (np.max(Z) - np.min(Z))\n",
    "    max_val = np.max(Z) + 0.1 * (np.max(Z) - np.min(Z))\n",
    "    ax.plot([minimum[0], minimum[0]], [minimum[1], minimum[1]], [min_val, max_val], linestyle=\"--\", \n",
    "            linewidth=2, color='red', label='Global minima of unconstrained optimization', zorder=1)\n",
    "\n",
    "    if \"Rastrigin\" in title:\n",
    "        # Increase transparency to better visualize the red dashed line\n",
    "        alpha = 0.3\n",
    "    else:\n",
    "        alpha = 0.6\n",
    "\n",
    "    # Create the surface plot\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=alpha, \n",
    "                          linewidth=0, antialiased=True, zorder=2)\n",
    "\n",
    "    # Add a contour plot at the bottom\n",
    "    cset = ax.contour(X, Y, Z, zdir='z', offset=np.min(Z), cmap='viridis')\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('f(X,Y)')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Add colorbar\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31fb37",
   "metadata": {},
   "source": [
    "\n",
    "#### **Algorithms for Unconstrained Optimization:**\n",
    "\n",
    "The process of finding the optimal solution to an unconstrained optimization problem is typically iterative and each iteration can be divided into two main steps: \n",
    " - Step 1: Determining the direction in which we can find an iterate with a lower function value. Common methods include gradient descent and Newton's method. \n",
    " - Step 2: Determining how big of a step we can take in the chosen direction to reduce the function value at the next iterate.  Backtracking line search is one of the simplest and most widely used strategies.  \n",
    "\n",
    "In the following, we will briefly introduce these algorithms.\n",
    "\n",
    "##### **Gradient Descent**\n",
    "\n",
    "Gradient descent (GD) is a first-order iterative optimization algorithm for finding the local minimum of a differentiable function.\n",
    "At each iteration, it updates the current estimate by moving in the direction of the steepest descent, which is the negative gradient of the function at that point.\n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}^{l+1} = \\boldsymbol{x}^l - \\alpha^l \\nabla f(\\boldsymbol{x}^l) \\,,\n",
    "$$\n",
    "\n",
    "where:\n",
    "   - $\\boldsymbol{x}^l$ is the current iterate,\n",
    "   - $\\nabla f(\\boldsymbol{x}^l)$ is the gradient of the objective function at $\\boldsymbol{x}^l$,\n",
    "   - $\\alpha^l > 0$ is the step size (or learning rate), which can be determined via a line search strategy.\n",
    "\n",
    "Gradient Descent guarantees convergence to a local minimum for nonlinear functions under appropriate conditions on the step size. However, it's also highly sensitive to the choice of step size—too small leads to slow convergence, while too large may cause divergence—and its inefficiency on ill-conditioned problems, where the optimization path can become highly zigzagged and slow.\n",
    "\n",
    "\n",
    "##### **Newton's Method**\n",
    "\n",
    "Newton's Method is a second-order optimization algorithm that uses both the gradient and the Hessian (second derivative) of the objective function to find a local minimum.\n",
    "At each iteration, it updates the current estimate by moving along the Newton direction, which accounts for the local curvature of the function.\n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}^{l+1} = \\boldsymbol{x}^l - \\alpha^l \\left[\\nabla^2 f(\\boldsymbol{x}^l)\\right]^{-1} \\nabla f(\\boldsymbol{x}^l) \\,,\n",
    "$$\n",
    "\n",
    "where $\\nabla^2 f(\\boldsymbol{x}^l)$ is the Hessian matrix of the objective function at $\\boldsymbol{x}^l$.\n",
    "\n",
    "\n",
    "When the Hessian is positive definite and the initial guess is sufficiently close to the minimizer, Newton's Method achieves quadratic convergence, making it significantly faster than first-order methods like gradient descent near the solution.\n",
    "\n",
    "\n",
    "\n",
    "##### **Line Search (Backtracking)**\n",
    "\n",
    "Line search is a subroutine in optimization algorithms that determines an appropriate step size along a given search direction. The goal is to ensure sufficient decrease in the objective function while avoiding overly small steps. One of the most common and simple methods is **Backtracking Line Search**. It starts with a relatively large initial step size and repeatedly reduces it until a sufficient decrease condition (typically the **Armijo condition**) is satisfied. The pseudocode of the algorithm is shown below:\n",
    "\n",
    " - Start with an initial step size $\\alpha = \\alpha_0$ (typically $\\alpha_0 \\in \\left(0,1\\right)$).\n",
    " - Check whether the **Armijo condition** holds: $f(\\boldsymbol{x}^l + \\alpha p^l) \\leq f(\\boldsymbol{x}^l) + c \\alpha \\nabla f(\\boldsymbol{x}^l)^T p^l$, where $c \\in (0,1)$ is a small constant (e.g., $10^{-4}$).\n",
    " - If the condition is not satisfied, shrink the step size by a factor $\\beta \\in (0,1)$ (e.g., $\\beta = 0.5$), that is, update $\\alpha \\leftarrow \\beta \\alpha$, and repeat the check.\n",
    " - Continue until the Armijo condition is satisfied.\n",
    "\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b72687",
   "metadata": {},
   "source": [
    "#### **Example 1.1: Manual Unconstrained Optimization Solver Implementation**  \n",
    "\n",
    "Based on the three algorithms introduced above, we now implement a solver for unconstrained optimization problems, which uses GD or Newton's method for finding the search direction, and applies the backtracking of the line search algorithm to determine a suitable step size. The implementation of the solver will follow the steps below:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;1\\) Initialize the algorithm parameters, including the starting point of the iteration $x_0$ and the line search parameters such as $\\alpha_0$, $\\beta$, and $c$;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2\\) Use the CasADi symbolic system to define the symbolic variable $x$, and construct the expressions for the objective functions: Quadratic, Rosenbrock, and Rastrigin;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3\\) Use automatic differentiation (Autodiff) to compute the Jacobian and Hessian of the objective function;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;4\\) Implement the main iteration loop:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i\\) Based on the precomputed Jacobian and Hessian information, determine the search direction using either Gradient Descent or Newton’s method;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ii\\) Use backtracking line search starting from $\\alpha_0$, progressively reducing the step size to find the largest \n",
    "$\\alpha$ that satisfies the Armijo condition;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; iii\\) Perform one iteration based on the search direction and step size, and check whether the convergence criterion is satisfied.\n",
    "\n",
    "*Note that: for the symbolic framework, please check out this material https://web.casadi.org/docs/#document-symbolic*. *Section 3.3 shows how to define the symbolic variables.*  *Section 3.9 shows how to use the automatic differentiation to symbolically compute the Jacobian and Hessian.*  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0db6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnconstrOptimizer:\n",
    "    def __init__(self, alpha_0 = 1.0, beta = 0.5, c = 1e-4):\n",
    "\n",
    "        self.func_flag = 'quadratic'\n",
    "\n",
    "        self.x_init = np.array([0.0, 0.0])\n",
    "\n",
    "        self.solution_trajectory = []\n",
    "        self.directions = []\n",
    "\n",
    "        self.x = ca.MX.sym('x', 2)\n",
    "        \n",
    "        # Hyperparameters for line search\n",
    "        self.alpha_0 = alpha_0\n",
    "        self.beta = beta\n",
    "        self.c = c\n",
    "\n",
    "    def set_objective(self, func_type='quadratic'):\n",
    "        self.func_flag = func_type\n",
    "\n",
    "        if func_type == 'quadratic':\n",
    "            expr = quadratic(self.x)\n",
    "            self.global_minima = quadratic_minimum\n",
    "\n",
    "        elif func_type == 'rosenbrock':\n",
    "            expr = rosenbrock(self.x)\n",
    "            self.global_minima = rosenbrock_minimum\n",
    "\n",
    "        elif func_type == 'rastrigin':\n",
    "            rastrigin = rastrigin_setup(ca)\n",
    "            expr = rastrigin(self.x)\n",
    "            self.global_minima = rastrigin_minimum\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown function type.\")\n",
    "\n",
    "        self.expr = expr\n",
    "        self.f = ca.Function('f', [self.x], [expr])\n",
    "        self.grad_f = ca.Function('grad_f', [self.x], [ca.gradient(expr, self.x)])\n",
    "        self.hess_f = ca.Function('hess_f', [self.x], [ca.hessian(expr, self.x)[0]])\n",
    "\n",
    "    def solve(self, x_init, method='gd', max_step=100, tol=1e-3):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.x_init = np.array(x_init, dtype=np.float64)\n",
    "        self.method = method\n",
    "        self.tol = tol\n",
    "        self.max_step = max_step\n",
    "\n",
    "        self.solution_trajectory = [self.x_init.copy()]\n",
    "        self.directions = []\n",
    "\n",
    "        x_val = np.copy(self.x_init)\n",
    "\n",
    "        for iter in range(self.max_step):\n",
    "            grad = self.grad_f(x_val).full().flatten()\n",
    "            hess = self.hess_f(x_val).full()\n",
    "\n",
    "            # Search direction\n",
    "            if self.method == 'gd':\n",
    "                direction = -grad\n",
    "\n",
    "            elif self.method == 'newton':\n",
    "                direction = -np.linalg.solve(hess + 1e-8*np.eye(2), grad)\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(\"Method must be 'gd' or 'newton'\")\n",
    "\n",
    "            descent = grad @ direction\n",
    "            if abs(descent) < self.tol:\n",
    "                print(f\"Optimization completed in {iter} steps, converging to a local minimum.\")\n",
    "                break\n",
    "\n",
    "            # Line search (backtracking)\n",
    "            alpha = self.alpha_0\n",
    "            f0 = float(self.f(x_val))\n",
    "            while float(self.f(x_val + alpha * direction)) > f0 + self.c * alpha * descent:\n",
    "                alpha *= self.beta\n",
    "            \n",
    "            # Update\n",
    "            x_val = x_val + alpha * direction\n",
    "            self.solution_trajectory.append(x_val.copy())\n",
    "            self.directions.append(direction.copy())\n",
    "        \n",
    "        else:\n",
    "            print(f\"{max_step} steps passed, still not converging to a local minimum.\")\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Total computation time: {total_time} s, average computation time per cycle: {total_time/iter} s.\")\n",
    "\n",
    "    def plot_results(self):\n",
    "        sol = np.array(self.solution_trajectory)\n",
    "\n",
    "        x_max = max(5, np.max(sol[:, 0]))\n",
    "        x_min = min(-5, np.min(sol[:, 0]))\n",
    "        y_max = max(5, np.max(sol[:, 1]))\n",
    "        y_min = min(-5, np.min(sol[:, 1]))\n",
    "\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.f(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "        # Global Optima\n",
    "        ax.plot(self.global_minima[0], self.global_minima[1], marker='*', markersize=15,\n",
    "                color='red', label='Global minima of unconstrained optimization', zorder=10)\n",
    "\n",
    "        # Optimization Trajectory\n",
    "        ax.plot(sol[:, 0], sol[:, 1], marker='d', markersize=4,\n",
    "                color='orange', label='Trajectory', zorder=10)\n",
    "        ax.plot(sol[0, 0], sol[0, 1], color='darkorange', marker='o', markersize=8, label='Initial guess', zorder=11)\n",
    "        ax.plot(sol[-1, 0], sol[-1, 1], 'gs', label='Optimal solution from solver', zorder=11)\n",
    "\n",
    "        ax.set_title(f'Optimization Trajectory with {self.func_flag.capitalize()} Function')\n",
    "        ax.set_xlabel('x1')\n",
    "        ax.set_ylabel('x2')\n",
    "        ax.legend()\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b9ba3",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 1.2: Using Implemented Solvers**\n",
    "\n",
    "Starting with a simple scenario, we first attempt to solve the quadratic objective function using the above unconstrained optimization algorithms. The quadratic function is a simple convex function, and thus can be directly optimized using Gradient Descent. The steps are as follows:\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`(the default parameter settings can be used directly);\n",
    "\n",
    "2\\) Set the objective function to be `quadratic`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `gd` and other solver parameters as follows;\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c7012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quadratic cost + GD solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('quadratic')\n",
    "opt.solve(x_init=[-3, 3], method='gd', max_step=100)\n",
    "opt.plot_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7bad5",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "This figure illustrates the performance of GD in optimizing a quadratic objective function. Since quadratic functions are strongly convex with smooth curvature, GD ensures global convergence and follows a stable descent path. The trajectory steadily approaches the global minimum at the origin, demonstrating GD’s efficiency, especially when the Hessian has a well-conditioned structure. The log-scaled contour lines highlight the rapid cost reduction in early iterations and the slower convergence near the minimum, highlighting the importance of step size adaptation strategies like backtracking.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe79d1",
   "metadata": {},
   "source": [
    "##### **Example 1.3: Using Implemented Solver to Optimize the Rosenbrock Function**\n",
    "\n",
    "Now let us consider a more challenging scenario by choosing the Rosenbrock function as the objective. Its global minimum lies at $[1.0,1.0]$, but the function is notoriously difficult to optimize due to its narrow, curved valley and steep walls, which can easily mislead simple gradient-based methods. We will attempt to optimize it using GD and observe the resulting behavior.\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`;\n",
    "\n",
    "2\\) Set the objective function to be `rosenbrock`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `gd` and the maximal step number to be 2000~5000;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Hint: you may try the maximal step number for both lower and upper limit, which will lead to different optimization results*\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock cost + GD solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('rosenbrock')\n",
    "opt.solve(x_init=[-3.0, 3.0], method='gd', max_step=5000)  # max_step: 2000 TO 5000\n",
    "opt.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6971f",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "This figure shows the optimization trajectory of gradient descent applied to the Rosenbrock function. Due to the function’s narrow, curved valley and sharp gradients across directions, GD initially struggles to follow the optimal path and exhibits zigzag behavior as it gradually aligns with the valley floor. The trajectory eventually begins to converge toward the global minimum, but the progress is much slower compared to optimizing a quadratic function. **This highlights the limitations of GD in ill-conditioned landscapes, where the local curvature causes inefficient updates unless the step size is carefully controlled.** With around 5000 iterations, convergence to the minimum can be achieved, but at a significantly higher computational cost.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e174653",
   "metadata": {},
   "source": [
    "As an alternative approach to mitigate the zigzagging behavior often observed in GD, **we can use a smaller initial step size**. This can be achieved by adjusting the initial step length parameter $\\alpha_0$ in the backtracking line search algorithm. In our current implementation, the default value of $\\alpha_0$ is 1. We now change it to 0.1 and rerun the optimization algorithm to observe how the convergence behavior is affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller intial step size for backtracking\n",
    "alpha_0 = 0.1\n",
    "\n",
    "# Rosenbrock cost + GD solver\n",
    "opt = UnconstrOptimizer(alpha_0=alpha_0)\n",
    "opt.set_objective('rosenbrock')\n",
    "opt.solve(x_init=[-3.0, 3.0], method='gd', max_step=5000)  # max_step: 2000 TO 5000\n",
    "opt.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddd566",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "From the results, we observe that after reducing the step size, the optimization trajectory becomes much smoother and aligns more closely with the curved valley of the Rosenbrock function, indicating improved stability and reduced oscillations. **However, this comes at the cost of requiring more iterations to reach the optimum, which implies increased computational overhead.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a316880",
   "metadata": {},
   "source": [
    "<blockquote style=\"padding-top: 20px; padding-bottom: 10px;\">\n",
    "\n",
    "##### **🔍 Hands-on Exploration: Line Search**\n",
    "\n",
    "To better understand the impact of line search on optimization performance, here you are encouraged to:\n",
    "\n",
    "- Experiment with the different hyperparameter configurations in backtracking line search, namely $\\alpha_0$, $\\beta$, and $c$;\n",
    "\n",
    "- Implement your own line search stopping condition. In addition to the Armijo condition, another commonly used criterion is the Strong Wolfe condition (see [Wolfe conditions](https://en.wikipedia.org/wiki/Wolfe_conditions)).\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e4766",
   "metadata": {},
   "source": [
    "##### **Example 1.4: Using Newton's Method to Optimize the Rosenbrock Function**\n",
    "\n",
    "Given the poor performance of GD on the Rosenbrock function, we now attempt to optimize it using Newton’s method. Compared to GD, Newton’s method leverages second-order curvature information, allowing it to take more informed steps and converge faster near the optimum, especially in ill-conditioned landscapes.\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`;\n",
    "\n",
    "2\\) Set the objective function to be `rosenbrock`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `newton` and other solver parameters as follows;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Hint: now you can use a much smaller number for the maximal step number.*\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock cost + newton solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('rosenbrock')\n",
    "opt.solve(x_init=[-3, 3], method='newton', max_step=100)\n",
    "opt.plot_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c524301b",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "This figure shows the optimization trajectory of Newton's method applied to the Rosenbrock function. Unlike Gradient Descent, Newton’s method successfully converges to the global optimum at $[1.0,1.0]$ in fewer than 50 iterations, demonstrating significantly higher efficiency. The trajectory closely follows the curved valley, highlighting **Newton's ability to incorporate second-order curvature information for better step directions**, especially in narrow and ill-conditioned landscapes. This result underscores the strength of Newton’s method in adapting to the local geometry of complex objective functions.\n",
    "\n",
    "However, Newton's method also has notable drawbacks when comparing with GD: **it requires computing and inverting the Hessian matrix, which can be computationally expensive and numerically unstable**, especially in high-dimensional problems. Therefore, in practical applications, the choice of direction search algorithm should be guided by the structure and properties of the specific objective function.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf70259",
   "metadata": {},
   "source": [
    "##### **Example 1.5: Using Newton's Method to Optimize the Rastrigin Function**\n",
    "\n",
    "Now let us consider a more complex scenario as the testbed for Newton’s method: the Rastrigin function, which is highly non-convex and characterized by a large number of regularly spaced local minima, making it particularly challenging for local optimization methods that rely on gradient and curvature information.\n",
    "\n",
    "1\\) Instantiate the unconstrained solver class `UnconstrOptimizer`;\n",
    "\n",
    "2\\) Set the objective function to be `rastrigin`;\n",
    "\n",
    "3\\) Call solving loop function, set the direction searching method to be `newton` and other solver parameters as follows;\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*Hint: you may try different initializations, which will lead to different optimization results. Recommended initial states to test are:*\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_0^{(1)} = \\begin{bmatrix}-0.8\\\\3.2\\end{bmatrix}, \n",
    "\\quad \\boldsymbol{x}_0^{(2)} = \\begin{bmatrix}-0.7\\\\3.3\\end{bmatrix}, \n",
    "\\quad \\boldsymbol{x}_0^{(3)} = \\begin{bmatrix}-0.3\\\\0.3\\end{bmatrix}, \n",
    "\\quad \\boldsymbol{x}_0^{(4)} = \\begin{bmatrix}-0.2\\\\0.2\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "4\\) Plot the result and observe the optimization trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastrigin cost + newton solver\n",
    "opt = UnconstrOptimizer()\n",
    "opt.set_objective('rastrigin')\n",
    "opt.solve(x_init=[-0.8, 3.2], method='newton', max_step=100) # x_init: [-0.8, 3.2] OR [-0.7, 3.3] OR [-0.3, 0.3] OR [-0.2, 0.2]\n",
    "opt.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586058ad",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "The experimental results show that when applying Newton’s method to non-convex objective functions, the optimization trajectory is prone to getting trapped in local minima. Moreover, whether the algorithm converges to a global or local optimum largely depends on the initial starting point—Newton’s method typically converges to the nearest stationary point. **This highlights the importance of initialization: the quality of the final solution is highly sensitive to where the optimization begins.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a172471",
   "metadata": {},
   "source": [
    "<blockquote style=\"padding-top: 20px; padding-bottom: 10px;\">\n",
    "\n",
    "##### **🔍 Hands-on Exploration: Go Beyond Local Minima**\n",
    "\n",
    "Since Newton’s method is highly sensitive to initialization, you are encouraged to **think creatively about how to increase the chances of reaching the global optimum**. Consider experimenting with multiple starting points, designing smarter initialization heuristics, or combining global exploration with local refinement. The goal is not just to run the algorithm, but to strategize around it—can you develop a method that consistently avoids poor local solutions?\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c832be",
   "metadata": {},
   "source": [
    "##### **Example 1.6: Using Built-in Solvers**\n",
    "\n",
    "While the previous section focused on building unconstrained optimization solvers from scratch using backtracking line search and descent directions (e.g., gradient or Newton-based), this was primarily intended to illustrate the fundamental ideas behind iterative optimization algorithms.\n",
    "\n",
    "In practice, one can take advantage of robust and efficient solvers available in modern libraries. In Python, the `scipy.optimize.minimize function` offers a range of algorithms for unconstrained and constrained problems. Below are some commonly used methods:\n",
    "\n",
    "- `BFGS` (Broyden–Fletcher–Goldfarb–Shanno): A quasi-Newton method that approximates the Hessian matrix using only gradient information. It is efficient for medium-scale problems and does not require computing second derivatives.\n",
    "\n",
    "- `L-BFGS-B` (Limited-memory BFGS with Box constraints): A memory-efficient version of BFGS that is suitable for large-scale problems. It allows simple bound constraints on variables, making it useful for problems that are “mostly” unconstrained but still have variable bounds.\n",
    "\n",
    "- `Newton-CG` (Newton-Conjugate Gradient): A Newton-type method that uses a conjugate gradient approach to compute the Newton step without forming the full Hessian. It is effective when the Hessian-vector product can be computed efficiently.\n",
    "\n",
    "- `trust-constr` (Trust Region Constrained): A versatile trust-region method that handles both equality and inequality constraints. For unconstrained problems, it behaves similarly to other second-order trust-region solvers and is suitable when higher accuracy is needed.\n",
    "\n",
    "To apply these solvers, users typically need to provide:\n",
    "\n",
    "- **Objective function**: a callable function returning a scalar value.\n",
    "\n",
    "- **Initial guess**: starting point for the optimization.\n",
    "\n",
    "- **(Optional)**: gradient (Jacobian), Hessian, or Hessian-vector product, depending on the solver.\n",
    "\n",
    "- **(Optional)**: method-specific parameters such as maximum iterations, tolerances, etc.\n",
    "\n",
    "For example, using `scipy.optimize.minimize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "objective = 'quadratic' # 'quadratic' OR 'rosenbrock' OR 'rastrigin'\n",
    "\n",
    "rastrigin = rastrigin_setup(np)\n",
    "\n",
    "# Define the objective function\n",
    "def f(x):\n",
    "    if objective == 'quadratic':\n",
    "        return quadratic(x)\n",
    "    elif objective == 'rosenbrock':\n",
    "        return rosenbrock(x)\n",
    "    elif objective == 'rastrigin':\n",
    "        return rastrigin(x)\n",
    "\n",
    "# Set global minima for plotting\n",
    "if objective == 'quadratic':\n",
    "    global_minima = quadratic_minimum\n",
    "elif objective == 'rosenbrock':\n",
    "    global_minima = rosenbrock_minimum\n",
    "elif objective == 'rastrigin':\n",
    "    global_minima = rastrigin_minimum\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "# Initial guess\n",
    "# as before, you are encouraged to play around the initial guess to see the influence\n",
    "x0 = [-3, 3]\n",
    "\n",
    "# Run optimization\n",
    "res = minimize(f, x0, method='BFGS')\n",
    "\n",
    "print(f\"Total computation time: {time.time() - start_time} sec.\")\n",
    "\n",
    "# Create a plot for result visualization\n",
    "x = np.linspace(-5, 5, 400)\n",
    "y = np.linspace(-5, 5, 400)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros_like(X)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        Z[i, j] = f([X[i, j], Y[i, j]])\n",
    "\n",
    "Z_log = np.log1p(Z)  # for better contrast\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "cbar = plt.colorbar(CS, ax=ax)\n",
    "cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "# Global minimum\n",
    "ax.plot(global_minima[0], global_minima[1], marker='*', markersize=15,\n",
    "        color='red', label='Global minima of unconstrained optimization', zorder=10)\n",
    "\n",
    "# Initial and final solutions\n",
    "ax.plot(x0[0], x0[1], color='darkorange', marker='o', markersize=8, label='Initial guess', zorder=11)\n",
    "ax.plot(res.x[0], res.x[1], 'gs', label='Optimal solution from solver', zorder=11)\n",
    "\n",
    "ax.set_title(f'Optimization Result with {objective.capitalize()} Function')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.legend()\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36552ee1",
   "metadata": {},
   "source": [
    "<blockquote style=\"padding-top: 20px; padding-bottom: 10px;\">\n",
    "\n",
    "##### **🔍 Hands-on Exploration: Parameters in `scipy.optimize.minimize` with BFGS**\n",
    "\n",
    "When using the `'BFGS'` method in `scipy.optimize.minimize`, a number of optional parameters can be provided to control optimization behavior and diagnostics (see https://docs.scipy.org/doc/scipy/reference/optimize.minimize-bfgs.html#optimize-minimize-bfgs). These are passed via the `options` dictionary:\n",
    "\n",
    "- `maxiter`: Sets the **maximum number of iterations** (default: `None`, i.e., algorithm-dependent).\n",
    "\n",
    "- `gtol`: The **gradient norm tolerance** for convergence. Optimization terminates when $\\|\\nabla f(x)\\|_\\infty < \\texttt{gtol}$. Default: `1e-5`.\n",
    "\n",
    "- `disp`: Whether to **print convergence messages** (`True` or `False`).\n",
    "\n",
    "- `return_all`: If `True`, returns a list of all iterates in `res.allvecs`.\n",
    "\n",
    "These can be passed using the `options` keyword argument in `minimize()`.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "\n",
    "        res = minimize(f, x0, method='BFGS', options={\n",
    "            \"disp\": True,\n",
    "            \"maxiter\": 100,\n",
    "            \"gtol\": 1e-6,\n",
    "            \"return_all\": True\n",
    "        })\n",
    "```\n",
    "\n",
    "*Note that: jac=... can also be specified to provide the gradient of the objective function. The Hessian is not required and will be approximated internally by the BFGS update.*\n",
    "\n",
    "</blockquote> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b4e7b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f5c42",
   "metadata": {},
   "source": [
    "### **Part (b): Constrained Optimization**\n",
    "\n",
    "As introduced above, a constrained optimization problem has the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{x}} \\quad & f(\\boldsymbol{x}) \\\\\n",
    "\\text{subject to} \\quad & h_i(\\boldsymbol{x}) = 0, \\quad \\forall i \\in \\{1, 2, \\dots, N\\}, \\\\\n",
    "& g_j(\\boldsymbol{x}) \\leq 0, \\quad \\forall j \\in \\{1, 2, \\dots, M\\} \\,.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To solve such problems, the **Karush-Kuhn-Tucker (KKT) conditions** provide necessary conditions for optimality under regularity assumptions. The idea is to construct the **Lagrangian**:\n",
    "\n",
    "$$\n",
    "\\Lambda(\\boldsymbol{x}, \\lambda, \\mu) = f(\\boldsymbol{x}) + \\sum_{i=1}^N \\lambda_i h_i(\\boldsymbol{x}) + \\sum_{j=1}^M \\mu_j g_j(\\boldsymbol{x}),\n",
    "$$\n",
    "\n",
    "and then enforce the following **KKT conditions**:\n",
    "\n",
    "- **Stationarity**:\n",
    "   $$\n",
    "   \\nabla_x \\Lambda(\\boldsymbol{x}^*, \\lambda^*, \\mu^*) = 0\n",
    "   $$\n",
    "\n",
    "- **Primal feasibility**:\n",
    "   $$\n",
    "   h_i(\\boldsymbol{x}^*) = 0, \\quad \\forall i, \\qquad g_j(\\boldsymbol{x}^*) \\leq 0, \\quad \\forall j\n",
    "   $$\n",
    "\n",
    "- **Dual feasibility**:\n",
    "   $$\n",
    "   \\mu_j^* \\geq 0, \\quad \\forall j\n",
    "   $$\n",
    "\n",
    "- **Complementary slackness**:\n",
    "   $$\n",
    "   \\mu_j^* \\cdot g_j(\\boldsymbol{x}^*) = 0, \\quad \\forall j\n",
    "   $$\n",
    "\n",
    "Together, these conditions characterize candidate optimal solutions for constrained nonlinear programming problems.\n",
    "\n",
    "Although the KKT conditions characterize optimal solutions for constrained optimization problems, they cannot be directly used to solve QP or NLP problems without additional numerical strategies. Specifically:\n",
    "\n",
    "- **KKT conditions are not algorithms** — they provide necessary optimality conditions but do not specify how to compute the solution.\n",
    "\n",
    "- **The KKT system itself can be complex** — even in QP problems, solving the KKT conditions leads to a linear system with complementarity constraints, which requires specialized numerical methods.\n",
    "\n",
    "- **In Sequential QP (an approach to solve NLP), KKT conditions are approximated iteratively** — each sequential QP (SQP) iteration constructs a local QP subproblem using linearized constraints and a quadratic approximation of the cost, and solving this subproblem involves solving the KKT system numerically.\n",
    "\n",
    "- **Modern solvers encapsulate the KKT logic internally** — tools like `qpOASES`, `OSQP`, and `Ipopt` handle all KKT-related computations, allowing users to focus on modeling rather than solver internals.\n",
    "\n",
    "Thus, while the KKT framework underlies QP and SQP theory, practical solution requires converting the conditions into structured numerical subproblems and solving them with dedicated algorithms and solvers, which we will introduce in the following sections.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4210aeab",
   "metadata": {},
   "source": [
    "#### **Example 2.1: Configuring Built-in Quadratic Programming Solvers**  \n",
    "\n",
    "\n",
    "Let us first consider a simple variant of the nonlinear programming (NLP) problem: the quadratic programming (QP) problem. A QP problem is defined as an optimization problem where the objective function is quadratic and the constraints are linear. It follows the standard form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2} \\boldsymbol{x}^\\top \\boldsymbol{H} \\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x} \\\\\n",
    "\\text{s.t.} \\quad & \\boldsymbol{A}_{\\text{eq}} \\boldsymbol{x} = \\boldsymbol{b}_{\\text{eq}}\\\\\n",
    "                  & \\boldsymbol{A}_{\\text{ineq}} \\boldsymbol{x} \\leq \\boldsymbol{b}_{\\text{ineq}}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "Here, $\\boldsymbol{H} \\in \\mathbb{R}^{n \\times n}$ is a symmetric matrix defining the curvature of the cost, and $\\boldsymbol{g} \\in \\mathbb{R}^n$ defines the linear component of the cost. The matrices $\\boldsymbol{A}_{\\text{eq}} \\in \\mathbb{R}^{N \\times n}, \\boldsymbol{b}_{\\text{eq}} \\in \\mathbb{R}^{N}, \\boldsymbol{A}_{\\text{ineq}}\\in \\mathbb{R}^{M \\times n},$ and $\\boldsymbol{b}_{\\text{ineq}} \\in \\mathbb{R}^{M}$ describe the equality and inequality constraints, respectively.\n",
    "\n",
    "Quadratic programming (QP) problems can be solved by deriving and solving the associated Karush-Kuhn-Tucker (KKT) conditions. With the advancement of symbolic and numerical computing tools, modern QP solvers such as **OSQP** and **qpOASES** have automated this process. These solvers internally construct and solve the KKT system, allowing users to simply specify the objective function, constraints, and relevant optimization parameters through a well-defined interface.\n",
    "\n",
    "In this section, we choose **qpOASES** as the QP solver to demonstrate how to configure and use its interface for solving QP problems. It is worth noting that qpOASES is natively supported by CasADi, which allows it to be directly specified as the underlying QP solver within a CasADi-based optimization setup without requiring any separate package installation. The procedure follows the steps below:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1\\) Formulate the QP problem from external.** The standard form of a QP problem supported by CasADi is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{x}} \\quad & \\frac{1}{2} \\boldsymbol{x}^\\top \\boldsymbol{H} \\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x} \\\\\n",
    "\\text{s.t.} \\quad & \\boldsymbol{l}_{\\text{bg}} \\leq \\boldsymbol{A} \\boldsymbol{x} \\leq \\boldsymbol{u}_{\\text{bg}},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $\\boldsymbol{A} =\n",
    "\\begin{bmatrix}\n",
    "\\boldsymbol{A}_{\\text{eq}}\\\\\n",
    "\\boldsymbol{A}_{\\text{ineq}}\n",
    "\\end{bmatrix}$ defines linear constraints (inkl. equality and inequality constraints) with lower and upper bounds $\\boldsymbol{l}_{\\text{bg}} = \\begin{bmatrix}\n",
    "\\boldsymbol{b}_{\\text{eq}} \\\\\n",
    "-\\infty\n",
    "\\end{bmatrix}, \\quad\n",
    "\\boldsymbol{u}_{\\text{bg}} = \\begin{bmatrix}\n",
    "\\boldsymbol{b}_{\\text{eq}} \\\\\n",
    "\\boldsymbol{b}_{\\text{ineq}}\n",
    "\\end{bmatrix}$.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2\\) Define the QP structure in CasADi.** To pass the QP into CasADi, you need to define a dictionary containing:\n",
    "\n",
    "$$\n",
    "\\texttt{qp = \\{x: }\\boldsymbol{x}\\texttt{, f: }f(\\boldsymbol{x})\\texttt{, g: }g(\\boldsymbol{x})\\texttt{\\}},\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $f(\\boldsymbol{x})=\\frac{1}{2} \\boldsymbol{x}^\\top \\boldsymbol{H} \\boldsymbol{x} + \\boldsymbol{q}^\\top \\boldsymbol{x} $ is the quadratic objective and $g(\\boldsymbol{x}) = \\boldsymbol{A} \\boldsymbol{x}$ represents the constraint expressions.\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3\\) Configure and call the solver.** Create and configure the solver using:\n",
    "\n",
    "$$\n",
    "\\texttt{solver = nlpsol(\"solver\", \"qpoases\", qp)},\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and called with the necessary constraint bounds and initial guess:\n",
    "\n",
    "$$\n",
    "\\texttt{sol = solver(x0, lbg, ubg)}.\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The optimal solution can then be extracted from the returned dictionary.\n",
    "\n",
    "*Note that: for details on the QP solver in CasADi, check out https://web.casadi.org/docs/#quadratic-programming*  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPOptimizer:\n",
    "    def __init__(self):\n",
    "        self.x = ca.MX.sym('x', 2)\n",
    "        self.set_objective()\n",
    "        self.eq_params = None\n",
    "        self.ineq_params = None\n",
    "        self.optimum = None\n",
    "        self.x_init=None\n",
    "\n",
    "    def set_objective(self):\n",
    "        self.expr = 0.5 * (self.x[0]**2 / 4 + self.x[1]**2)\n",
    "        self.f = ca.Function('f', [self.x], [self.expr])\n",
    "        self.global_minima = np.array([0.0, 0.0])\n",
    "\n",
    "    def set_constraints(self, eq_params=None, ineq_params=None):\n",
    "        self.eq_params = eq_params\n",
    "        self.ineq_params = ineq_params\n",
    "\n",
    "    def solve(self, x_init=[0.0, 0.0]):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        self.x_init = x_init\n",
    "\n",
    "        A_list = []\n",
    "        lba = []\n",
    "        uba = []\n",
    "\n",
    "        if self.eq_params:\n",
    "            # a x_0 + b x_1 + c = 0\n",
    "            a, b, c = self.eq_params\n",
    "            A_list.append(np.array([[a, b]]))\n",
    "            lba.append(-c)\n",
    "            uba.append(-c)\n",
    "\n",
    "        if self.ineq_params:\n",
    "            # a x_0 + b x_1 + c <= 0\n",
    "            a, b, c = self.ineq_params\n",
    "            A_list.append(np.array([[a, b]]))\n",
    "            lba.append(-np.inf)\n",
    "            uba.append(-c)\n",
    "\n",
    "        A_total = np.vstack(A_list) if A_list else np.zeros((0, 2))\n",
    "        lba = np.array(lba)\n",
    "        uba = np.array(uba)\n",
    "\n",
    "        qp = {\n",
    "            'x': self.x,\n",
    "            'f': self.expr,\n",
    "            'g': ca.mtimes(ca.DM(A_total), self.x)\n",
    "        }\n",
    "        \n",
    "        solver = ca.qpsol('solver', 'qpoases', qp)\n",
    "\n",
    "        sol = solver(x0=x_init, lbg=lba, ubg=uba)\n",
    "\n",
    "        self.optimum = sol['x'].full().flatten()\n",
    "\n",
    "        print(f\"Total computation time: {time.time() - start_time} s.\")\n",
    "        \n",
    "        return self.optimum.tolist()\n",
    "\n",
    "    def plot_results(self):\n",
    "        x_max = 2.5\n",
    "        x_min = -2.5\n",
    "        y_max = 2.5\n",
    "        y_min = -2.5\n",
    "\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.f(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "        if self.eq_params:\n",
    "            a, b, c = self.eq_params\n",
    "            if b != 0:\n",
    "                x_eq = np.linspace(x_min, x_max, 400)\n",
    "                y_eq = (-a * x_eq - c) / b\n",
    "                ax.plot(x_eq, y_eq, 'k--', linewidth=2, label='Equality Constraint')\n",
    "            else:\n",
    "                x_eq = -c / a\n",
    "                ax.axvline(x_eq, color='k', linestyle='--', linewidth=2, label='Equality Constraint')\n",
    "\n",
    "        if self.ineq_params:\n",
    "            a, b, c = self.ineq_params\n",
    "            if b != 0:\n",
    "                x_ineq = np.linspace(x_min, x_max, 400)\n",
    "                y_ineq = (-a * x_ineq - c) / b\n",
    "                ax.plot(x_ineq, y_ineq, 'b-', linewidth=2, label='Inequality constraint')\n",
    "                ax.fill_between(x_ineq, y_ineq, y_max, color='blue', alpha=0.3)\n",
    "            else:\n",
    "                x_ineq = -c / a\n",
    "                ax.axvline(x_ineq, color='b', linestyle='-', linewidth=2, label='Inequality constraint')\n",
    "                if a > 0:\n",
    "                    ax.axvspan(x_min, x_ineq, color='blue', alpha=0.1)\n",
    "                else:\n",
    "                    ax.axvspan(x_ineq, x_max, color='blue', alpha=0.1)\n",
    "\n",
    "        if self.optimum is not None:\n",
    "            ax.plot(self.optimum[0], self.optimum[1], 'gs', markersize=10, label='Optimal solution from QP solver', zorder=11)\n",
    "\n",
    "        ax.plot(self.x_init[0], self.x_init[1], color='darkorange', marker='o', markersize=8, label='Initial guess', zorder=11)\n",
    "\n",
    "        ax.plot(self.global_minima[0], self.global_minima[1], '*', color='red', markersize=15, label='Global minima of unconstrained optimization')\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.set_xlabel('$x_0$')\n",
    "        ax.set_ylabel('$x_1$')\n",
    "        ax.set_title(\"Constrained Optimization Result (qpOASES)\")\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa88fdc",
   "metadata": {},
   "source": [
    "<blockquote style=\"padding-top: 20px; padding-bottom: 10px;\">\n",
    "\n",
    "##### **🔍 Hands-on Exploration: Parameters in QP solver configuration**\n",
    "\n",
    "A number of solver options can be specified when using **qpOASES** in CasADi to fine-tune the optimization behavior (see https://web.casadi.org/api/internal/d5/d43/classcasadi_1_1QpoasesInterface.html). The most relevant parameters include:\n",
    "\n",
    "- `printLevel`: Controls the verbosity of solver output. Accepts values such as `\"none\"`, `\"low\"`, `\"medium\"`, or `\"high\"`.\n",
    "\n",
    "- `maxIterations`: Sets the maximum number of iterations for the solver (default: 100).\n",
    "\n",
    "- `terminationTolerance`: Sets the accuracy required for convergence (default: 1e-5).\n",
    "\n",
    "- `boundTolerance`: Tolerance for how strictly bound constraints are enforced.\n",
    "\n",
    "These options can be passed into the solver via the `options` argument when calling `nlpsol`.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "            solver = nlpsol(\"solver\", \"qpoases\", qp, {\n",
    "                \"printLevel\": \"none\",\n",
    "                \"maxIterations\": 50,\n",
    "                \"terminationTolerance\": 1e-6\n",
    "            })\n",
    "```\n",
    "\n",
    "*Note that: in practice, for typical QP problems, it is sufficient to **use the default parameters** provided by qpOASES.*\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ceacac",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 2.2: Solving QPs with Built-in Solvers**\n",
    "\n",
    "\n",
    "1\\) Instantiate the class `QPOptimizer`;\n",
    "\n",
    "2\\) Specify the linear constraints in this optimization task with function `set_constraints()`; \n",
    "\n",
    "- Equality constraint: $\\quad [1 \\quad 1 \\quad -1] \\cdot \\begin{bmatrix} x_0\\\\ x_1\\\\ 1 \\end{bmatrix} = 0$  \n",
    "\n",
    "- Inequality constraint: $\\quad [1 \\quad -1 \\quad 0] \\cdot \\begin{bmatrix} x_0\\\\ x_1\\\\ 1 \\end{bmatrix} \\leq 0$  \n",
    "\n",
    "3\\) Set the initial guess as $[0 \\quad 1]$ and call function `solve()` to solve the QP problem;\n",
    "\n",
    "4\\) Call function `plot_results()` to visualize the results;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qpOASES for QP\n",
    "opt = QPOptimizer()\n",
    "opt.set_constraints(eq_params=(1, 1, -1), ineq_params=(1, -1, 0))\n",
    "opt.solve(x_init=[0.0, 1.0])\n",
    "opt.plot_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1cb8e",
   "metadata": {},
   "source": [
    "#### **Example 3.1: Manual Sequential QP Solver Implementation**  \n",
    "\n",
    "Sequential Quadratic Programming (SQP) is a widely used iterative method for solving NLP problems. The core idea of SQP is to approximate the NLP at each iteration with a quadratic programming (QP) subproblem, which captures the local curvature of the objective and constraints. The solution to this QP subproblem provides a search direction for updating the decision variables.\n",
    "\n",
    "An SQP algorithm typically follows these steps at each iteration:\n",
    "\n",
    "1. **Linearize the constraints** $ \\boldsymbol{h}(\\boldsymbol{x}) $ and $ \\boldsymbol{g}(\\boldsymbol{x}) $ using first-order Taylor expansions;  \n",
    "2. **Approximate the Hessian** of the Lagrangian $\\Lambda$ (e.g., using exact second-order information or BFGS approximation);  \n",
    "3. **Solve the resulting QP subproblem** to obtain a search direction $ \\boldsymbol{d} $;  \n",
    "4. **Perform a line search** or trust-region update along $ \\boldsymbol{d} $ to update the iterate $ \\boldsymbol{x} $;  \n",
    "5. **Repeat** until convergence criteria are met.\n",
    "\n",
    "Mathematically, the QP subproblem solved at each iteration takes the form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{d}} \\quad & \\frac{1}{2} \\boldsymbol{d}^\\top \\boldsymbol{H}_k \\boldsymbol{d} + \\nabla f(\\boldsymbol{x}_k)^\\top \\boldsymbol{d} \\\\\n",
    "\\text{s.t.} \\quad & \\boldsymbol{h}(\\boldsymbol{x}_k) + \\nabla \\boldsymbol{h}(\\boldsymbol{x}_k)^\\top \\boldsymbol{d} = 0, \\\\\n",
    "                  & \\boldsymbol{g}(\\boldsymbol{x}_k) + \\nabla \\boldsymbol{g}(\\boldsymbol{x}_k)^\\top \\boldsymbol{d} \\leq 0,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $ \\boldsymbol{H}_k $ is a (possibly approximated) Hessian of the Lagrangian at the current iterate $ \\boldsymbol{x}_k $.\n",
    "\n",
    "\n",
    "In this section, we demonstrate how to manually implement a **Sequential Quadratic Programming (SQP)** solver using CasADi. The solver is built from scratch by explicitly forming the Taylor expansion of the Lagrangian function, updating the Hessian at each iteration, and solving a Quadratic Programming (QP) subproblem using qpOASES, which is natively integrated into CasADi. This implementation gives full control over the optimization process and provides a transparent view of how SQP operates internally. The procedure follows the steps below:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;1\\) Formulate the nonlinear optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{x}} \\quad & f(\\boldsymbol{x}) \\\\\n",
    "\\text{s.t.} \\quad & \\boldsymbol{h}(\\boldsymbol{x}) = \\boldsymbol{0}, \\\\\n",
    "                  & \\boldsymbol{g}(\\boldsymbol{x}) \\leq \\boldsymbol{0},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $ f(\\boldsymbol{x}) $ is a nonlinear cost function, $ \\boldsymbol{h}(\\boldsymbol{x}) $ defines equality constraints, and $ \\boldsymbol{g}(\\boldsymbol{x}) $ defines inequality constraints.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2\\) Build symbolic derivatives and Lagrangi, the `SQPOptimizer` class computes:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  The **gradient** of the objective function,   \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  The **Jacobian** of equality and inequality constraints,   \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  The **Lagrangian function**,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  the **gradient and Hessian** of the Lagrangian with respect to $ \\boldsymbol{x} $,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  A **merit function** to measure constraint violation and guide line search.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;All symbolic derivatives are precompiled using CasADi’s automatic differentiation.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3\\) Construct and solve the following QP subproblem at each iteration\\:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{d}} \\quad & \\frac{1}{2} \\boldsymbol{d}^\\top H_k \\boldsymbol{d} + \\nabla f(\\boldsymbol{x}_k)^\\top \\boldsymbol{d} \\\\\n",
    "\\text{s.t.} \\quad & A_h \\boldsymbol{d} + h(\\boldsymbol{x}_k) = 0 \\\\\n",
    "                  & A_g \\boldsymbol{d} + g(\\boldsymbol{x}_k) \\leq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  $ H_k $ is the Hessian of the Lagrangian,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  $ A_h, A_g $ are the Jacobians of the constraints.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This QP is solved using CasADi’s interface to **qpOASES**. The primal step $ \\boldsymbol{d}_k $ and dual multipliers $ \\boldsymbol{\\lambda}_k $ are extracted from the QP solution.\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;4\\) Perform line search using the Lagrangian. By determining the constraint violation at each step, you can select step sizes that only lead to feasible iterates. In practice, often so-called merit functions are employed, which help to improve convergence especially from infeasible initial guesses. \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;5\\) Repeat SQP process until one of the following conditions is met:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  The primal step $ \\|\\boldsymbol{d}_k\\| $ is sufficiently small,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  The KKT residual is below tolerance,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  A maximum number of iterations is reached,\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;•  The QP subproblem becomes infeasible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c24ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQPOptimizer:\n",
    "    def __init__(self, f_func, eq_func=None, ineq_func=None, max_iter=50, tol=1e-6, only_feasible_steps=False, verbose=False):\n",
    "        self.f_func = f_func\n",
    "        self.eq_func = eq_func\n",
    "        self.ineq_func = ineq_func\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.trace = []\n",
    "        self.only_feasible_steps = only_feasible_steps\n",
    "\n",
    "        self.x_dim = f_func.size_in(0)[0]\n",
    "        self._setup_derivatives()\n",
    "\n",
    "    def _setup_derivatives(self):\n",
    "        x = ca.MX.sym('x', self.x_dim)\n",
    "        self.grad_f = ca.Function('grad_f', [x], [ca.gradient(self.f_func(x), x)])\n",
    "\n",
    "        if self.eq_func is not None:\n",
    "            self.grad_eq = ca.Function('grad_eq', [x], [ca.jacobian(self.eq_func(x), x)])\n",
    "        if self.ineq_func is not None:\n",
    "            self.grad_ineq = ca.Function('grad_ineq', [x], [ca.jacobian(self.ineq_func(x), x)])\n",
    "\n",
    "        lambda_dim = 0\n",
    "        if self.eq_func is not None:\n",
    "            lambda_dim += self.eq_func(x).size1()\n",
    "        if self.ineq_func is not None:\n",
    "            lambda_dim += self.ineq_func(x).size1()\n",
    "\n",
    "        lmbda = ca.MX.sym('lmbda', lambda_dim)\n",
    "        L = self.f_func(x)\n",
    "        idx = 0\n",
    "        self.num_equality_constraints = 0\n",
    "        self.num_inequality_constraints = 0\n",
    "\n",
    "        if self.eq_func is not None:\n",
    "            eq_val = self.eq_func(x)\n",
    "            self.num_equality_constraints = eq_val.size1()\n",
    "            for i in range(self.num_equality_constraints):\n",
    "                L += lmbda[idx] * eq_val[i]\n",
    "                idx += 1\n",
    "            \n",
    "        if self.ineq_func is not None:\n",
    "            ineq_val = self.ineq_func(x)\n",
    "            self.num_inequality_constraints = ineq_val.size1()\n",
    "            for i in range(self.num_inequality_constraints):\n",
    "                L += lmbda[idx] * ineq_val[i]\n",
    "                idx += 1\n",
    "\n",
    "        self.lagrangian = ca.Function('lagrangian', [x, lmbda], [L])\n",
    "        self.grad_lagrangian = ca.Function('grad_lagrangian', [x, lmbda], [ca.gradient(L, x)])\n",
    "        self.hess_L = ca.Function('hess_L', [x, lmbda], [ca.hessian(L, x)[0]])\n",
    "    \n",
    "        self.constraint_violation = ca.Function('constr_violation', [x], \n",
    "                                              [self._calculate_constraint_violation(x)])\n",
    "\n",
    "    def _calculate_constraint_violation(self, x):\n",
    "        \"\"\"Calculate the constraint violation for merit function.\"\"\"        \n",
    "        violations = []\n",
    "        \n",
    "        if self.eq_func is not None:\n",
    "            eq_val = self.eq_func(x)\n",
    "            for i in range(eq_val.size1()):\n",
    "                violations.append(ca.fabs(eq_val[i]))\n",
    "                \n",
    "        if self.ineq_func is not None:\n",
    "            ineq_val = self.ineq_func(x)\n",
    "            for i in range(ineq_val.size1()):\n",
    "                violations.append(ca.fmax(0, ineq_val[i]))\n",
    "                \n",
    "        if violations:\n",
    "            return ca.sum1(ca.vertcat(*violations))\n",
    "        else:\n",
    "            return ca.MX(0)\n",
    "\n",
    "    def solve(self, x0):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        x_k = np.array(x0).flatten()\n",
    "        lambda_k = np.zeros(self.num_equality_constraints + self.num_inequality_constraints)\n",
    "        # Initialize lambda_k with a positive value for inequality constraints\n",
    "        lambda_k[self.num_equality_constraints:] = 1.0\n",
    "        \n",
    "        H_k = np.eye(self.x_dim)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            self.trace.append(x_k.copy())\n",
    "\n",
    "            grad_f_k = np.array(self.grad_f(x_k).full()).flatten()\n",
    "\n",
    "            eq_val_k, grad_eq_k = None, None\n",
    "            ineq_val_k, grad_ineq_k = None, None\n",
    "            if self.eq_func is not None:\n",
    "                eq_val_k = np.array(self.eq_func(x_k).full()).flatten()\n",
    "                grad_eq_k = np.array(self.grad_eq(x_k).full())\n",
    "            if self.ineq_func is not None:\n",
    "                ineq_val_k = np.array(self.ineq_func(x_k).full()).flatten()\n",
    "                grad_ineq_k = np.array(self.grad_ineq(x_k).full())\n",
    "\n",
    "            H_k = np.array(self.hess_L(x_k, lambda_k).full())\n",
    "            # Make sure H_k is symmetric, it should be theoretically but does not have to be numerically\n",
    "            H_k = (H_k + H_k.T) / 2\n",
    "\n",
    "            eigvals = np.linalg.eigvalsh(H_k)\n",
    "            min_eig = np.min(eigvals)\n",
    "            if min_eig <= 1e-6:\n",
    "                H_k += (abs(min_eig) + 1e-4) * np.eye(H_k.shape[0])\n",
    "\n",
    "            # Solve QP\n",
    "            success, d_k, multipliers = self._solve_qp(\n",
    "                H_k,\n",
    "                grad_f_k,\n",
    "                grad_eq_k,\n",
    "                eq_val_k if eq_val_k is not None else None,\n",
    "                grad_ineq_k,\n",
    "                ineq_val_k if ineq_val_k is not None else None\n",
    "            )\n",
    "\n",
    "            if not success:\n",
    "                if self.verbose:\n",
    "                    print(f\"[Iter {iteration}] QP solver failed, early stop.\")\n",
    "                break\n",
    "\n",
    "            if np.linalg.norm(d_k) < self.tol:\n",
    "                self.trace.append(x_k + d_k[:self.x_dim])\n",
    "                if self.verbose:\n",
    "                    print(f\"[Iter {iteration}] Converged, step norm={np.linalg.norm(d_k):.2e}\")\n",
    "                break\n",
    "\n",
    "            # Line search (backtracking)\n",
    "            alpha = 0.9\n",
    "            beta = 0.5\n",
    "            c1 = 1e-4\n",
    "            lagrangian_current = self.lagrangian(x_k, lambda_k).full().flatten()[0]\n",
    "            lagrangian_grad_current = np.array(self.grad_lagrangian(x_k, lambda_k).full()).flatten()\n",
    "\n",
    "            while True:\n",
    "                x_trial = x_k + alpha * d_k\n",
    "                lambda_trial = multipliers\n",
    "                lagrangian_trial = self.lagrangian(x_trial, lambda_trial).full().flatten()[0]\n",
    "\n",
    "                if self.constraint_violation(x_trial).full().flatten()[0] <= 1e-6 or not self.only_feasible_steps:\n",
    "                    if lagrangian_trial <= lagrangian_current + c1 * alpha * np.dot(lagrangian_grad_current, d_k):\n",
    "                        break\n",
    "                alpha *= beta\n",
    "                if alpha < 1e-8:\n",
    "                    break\n",
    "\n",
    "            x_next = x_k + alpha * d_k\n",
    "            # Use the multipliers from the QP solver\n",
    "            lambda_next = multipliers\n",
    "\n",
    "            x_k = x_next\n",
    "            lambda_k = lambda_next\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"[Iter {iteration}] Cost: {lagrangian_current:.6f}, alpha={alpha:.3f}, step norm={np.linalg.norm(d_k):.2e}\")\n",
    "\n",
    "            print(f\"Total computation time: {time.time() - start_time} sec.\")\n",
    "\n",
    "        return x_k\n",
    "\n",
    "    def _solve_qp(self, H, f, A_eq, b_eq, A_ineq, b_ineq):\n",
    "        x = ca.MX.sym('x', H.shape[1])\n",
    "        f = f.reshape((1, -1))\n",
    "        cost = 0.5 * ca.mtimes([x.T, H, x]) + ca.mtimes(f, x)\n",
    "\n",
    "        constraints = []\n",
    "        lbg = []\n",
    "        ubg = []\n",
    "\n",
    "        if A_eq is not None and A_eq.shape[0] > 0:\n",
    "            constraints.append(ca.mtimes(A_eq, x) + b_eq)\n",
    "            lbg.append(np.zeros(A_eq.shape[0]))\n",
    "            ubg.append(np.zeros(A_eq.shape[0]))\n",
    "\n",
    "        if A_ineq is not None and A_ineq.shape[0] > 0:\n",
    "            constraints.append(ca.mtimes(A_ineq, x) + b_ineq)\n",
    "            ubg.append(np.zeros(A_ineq.shape[0]))\n",
    "            lbg.append(np.full(A_ineq.shape[0], -np.inf))\n",
    "\n",
    "        if constraints:\n",
    "            g = ca.vertcat(*constraints)\n",
    "            lbg = np.concatenate(lbg)\n",
    "            ubg = np.concatenate(ubg)\n",
    "        else:\n",
    "            g = ca.MX()\n",
    "            lbg = np.array([])\n",
    "            ubg = np.array([])\n",
    "\n",
    "        qp = {'x': x, 'f': cost, 'g': g}\n",
    "        solver = ca.qpsol('solver', 'qpoases', qp, {'error_on_fail': False})\n",
    "        sol = solver(lbg=lbg, ubg=ubg)\n",
    "\n",
    "        stats = solver.stats()\n",
    "        success = not bool(stats['return_status'] == 'Infeasible_Problem_Detected')\n",
    "\n",
    "        return success, np.array(sol['x'].full()).flatten(), np.array(sol['lam_g'].full()).flatten()\n",
    "\n",
    "    def plot_trajectory(self, global_minima=None):\n",
    "        x_max, x_min, y_max, y_min = 2.5, -2.5, 2.5, -2.5\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.f_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    " \n",
    "        # Equality constraint\n",
    "        if self.eq_func is not None:\n",
    "            eq_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    eq_vals[i, j] = self.eq_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, eq_vals, levels=[0], colors='k', linewidths=2, linestyles='--')\n",
    "            ax.plot([], [], color='black', linestyle='--', linewidth=2, label='Equality constraint')\n",
    "\n",
    "        # Inequality constraint\n",
    "        if self.ineq_func is not None:\n",
    "            ineq_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    ineq_vals[i, j] = self.ineq_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, ineq_vals, levels=[0], colors='b', linewidths=2)\n",
    "            ax.plot([], [], color='blue', linewidth=2, label='Inequality constraint')\n",
    "            ax.contourf(X, Y, ineq_vals, levels=[-np.inf, 0], colors='blue', alpha=0.3)\n",
    "\n",
    "        if self.trace:\n",
    "            traj = np.array(self.trace)\n",
    "            ax.plot(traj[:, 0], traj[:, 1], 'd-', color='orange', label='SQP Trajectory')\n",
    "            ax.plot(traj[-1, 0], traj[-1, 1], 'gs', markersize=10, label='Optimal solution from SQP solver', zorder=11)\n",
    "            ax.plot(traj[0, 0], traj[0, 1], color='darkorange', marker='o', markersize=8, label='Initial guess', zorder=11)\n",
    "\n",
    "        if global_minima is not None:\n",
    "            ax.plot(global_minima[0], global_minima[1], '*', color='red', markersize=15, label='Global minima of unconstrained optimization')\n",
    "\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.set_xlabel('$x_0$')\n",
    "        ax.set_ylabel('$x_1$')\n",
    "        ax.set_title(\"SQP Optimization Trajectory\")\n",
    "        ax.grid(True)\n",
    "        ax.legend(loc='lower left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9fb4d6",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 3.2: Using Implemented SQP Solver for Nonlinear Programming**\n",
    "\n",
    "1\\) Specify the objective function as follows;\n",
    "\n",
    "- Quadratic function: $f(\\boldsymbol{x}) = \\frac{1}{8} x_0^2 + \\frac{1}{2} x_1^2$\n",
    "\n",
    "2\\) Specify the nonlinear constraints as follows; \n",
    "\n",
    "- Equality constraint: None  \n",
    "\n",
    "- Inequality constraint: $h(\\boldsymbol{x}) = {(x_0 - 1)}^2 + 3 {(x_1 - 1.5)}^2 - 1$ (Ellipsoid) \n",
    "\n",
    "3\\) Instantiate the class `SQPOptimizer` with pre-defined $f(\\boldsymbol{x})$, $g(\\boldsymbol{x})$ and $h(\\boldsymbol{x})$;\n",
    "\n",
    "4\\) Set the initial guess as $[1.5 \\quad 1.5]$ and call function `solve()` to solve the NLP problem;\n",
    "\n",
    "5\\) Call function `plot_results()` to visualize the results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define symbols\n",
    "x = ca.MX.sym('x', 2)\n",
    "\n",
    "# Objective: simple quadratic\n",
    "f = ca.Function(\"f\", [x], [0.5 * (x[0]**2 / 4 + x[1]**2)])\n",
    "# Inequality constraint: ellipsoid\n",
    "g = ca.Function(\"g\", [x], [(x[0] - 1)**2 + (x[1] - 1.5)**2 * 3 - 1])  # g(x) <= 0\n",
    "# Equality constraint: None\n",
    "h = None  \n",
    "\n",
    "# Instantiate solver\n",
    "sqp_solver = SQPOptimizer(\n",
    "    f_func=f,\n",
    "    eq_func=h,\n",
    "    ineq_func=g,\n",
    "    max_iter=50,\n",
    "    tol=1e-6,\n",
    "    only_feasible_steps=True,  # if True, only feasible step sizes are accepted\n",
    "    verbose=True \n",
    ")\n",
    "\n",
    "# Initial point\n",
    "x_init = np.array([1.5, 1.5])\n",
    "\n",
    "# Solve\n",
    "sol = sqp_solver.solve(x_init)\n",
    "\n",
    "print(\"Optimal Solution Found:\", sol)\n",
    "\n",
    "# Plot\n",
    "sqp_solver.plot_trajectory(global_minima=np.array([0.0, 0.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d0b800",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 3.3: Configuring Built-in SQP Solvers for NLP**\n",
    "\n",
    "In the previous section, we introduced the SQP method and provided a custom implementation that manually performs linearizations, constructs QP subproblems, and iteratively updates the solution. While such an implementation is valuable for understanding the inner workings of SQP and customizing its behavior, in practical applications it is often more convenient to leverage existing optimization libraries.\n",
    "\n",
    "Modern numerical tools like **CasADi** provide an implementation of SQP through the built-in `\"sqpmethod\"` solver, which automates the above process. The user only needs to provide the nonlinear objective and constraint functions, and CasADi internally handles the linearizations, QP construction, and iterative updates.\n",
    "\n",
    "The configuration of a SQP solver is similar to the QP solver, which follows the steps:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**1) Formulate the NLP problem.** The standard form of a generic nonlinear programming (NLP) problem is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{\\boldsymbol{x}} \\quad & f(\\boldsymbol{x}) \\\\\n",
    "\\text{s.t.} \\quad & \\boldsymbol{h}(\\boldsymbol{x}) = \\boldsymbol{0}, \\\\\n",
    "                  & \\boldsymbol{g}(\\boldsymbol{x}) \\leq \\boldsymbol{0},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $ f(\\boldsymbol{x}) $ is a nonlinear cost function, $ \\boldsymbol{h}(\\boldsymbol{x}) $ defines equality constraints, and $ \\boldsymbol{g}(\\boldsymbol{x}) $ defines inequality constraints.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**2) Define the NLP structure in CasADi.** To pass the NLP into CasADi, you need to define a dictionary:\n",
    "\n",
    "$$\n",
    "\\texttt{nlp = \\{x: } \\boldsymbol{x} \\texttt{, f: } f(\\boldsymbol{x}) \\texttt{, g: } \\boldsymbol{c}(\\boldsymbol{x}) \\texttt{\\}},\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;where $ \\boldsymbol{x} \\in \\mathbb{R}^n $ is the optimization variable, $ f(\\boldsymbol{x}) $ is the cost function, and $ \\boldsymbol{c}(\\boldsymbol{x}) $ combines all constraints:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{c}(\\boldsymbol{x}) =\n",
    "\\begin{bmatrix}\n",
    "\\boldsymbol{h}(\\boldsymbol{x}) \\\\\n",
    "\\boldsymbol{g}(\\boldsymbol{x})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The corresponding lower and upper bounds are:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{l}_c =\n",
    "\\begin{bmatrix}\n",
    "\\boldsymbol{0} \\\\\n",
    "-\\infty\n",
    "\\end{bmatrix}, \\quad\n",
    "\\boldsymbol{u}_c =\n",
    "\\begin{bmatrix}\n",
    "\\boldsymbol{0} \\\\\n",
    "\\boldsymbol{0}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**3) Configure and call the solver.** Create the SQP solver by specifying the backend as `\"sqpmethod\"`:\n",
    "\n",
    "$$\n",
    "\\texttt{solver = nlpsol(\"solver\", \"sqpmethod\", nlp)}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Then solve the problem with an initial guess and the constraint bounds:\n",
    "\n",
    "$$\n",
    "\\texttt{sol = solver(x0, lbg = } \\boldsymbol{l}_c \\texttt{, ubg = } \\boldsymbol{u}_c \\texttt{)}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The optimal solution can be extracted from `sol['x']`.\n",
    "\n",
    "*Note that: for more detail on NLP solvers in CasADi, check out this material https://web.casadi.org/docs/#nonlinear-programming.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dfc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQPOptimizer:\n",
    "    def __init__(self, objective_func, eq_func=None, ineq_func=None, global_minima=None):\n",
    "        self.objective_func = objective_func\n",
    "        self.eq_func = eq_func\n",
    "        self.ineq_func = ineq_func\n",
    "        self.global_minima = np.array(global_minima) if global_minima is not None else None\n",
    "\n",
    "        self.x_dim = self.objective_func.size_in(0)[0]\n",
    "        self.x_init = None\n",
    "        self.x_end = None\n",
    "        self._setup_nlp()\n",
    "\n",
    "    def _setup_nlp(self):\n",
    "        x = ca.MX.sym('x', self.x_dim)\n",
    "        cost = self.objective_func(x)\n",
    "\n",
    "        constraints = []\n",
    "        lbg = []\n",
    "        ubg = []\n",
    "\n",
    "        if self.eq_func is not None:\n",
    "            # eq_func(x) = 0\n",
    "            eq_expr = self.eq_func(x)\n",
    "            constraints.append(eq_expr)\n",
    "            lbg.append(np.zeros(eq_expr.shape[0]))\n",
    "            ubg.append(np.zeros(eq_expr.shape[0]))\n",
    "\n",
    "        if self.ineq_func is not None:\n",
    "            # ineq_func(x) <= 0\n",
    "            ineq_expr = self.ineq_func(x)\n",
    "            constraints.append(ineq_expr)\n",
    "            lbg.append(-np.inf * np.ones(ineq_expr.shape[0]))\n",
    "            ubg.append(np.zeros(ineq_expr.shape[0]))\n",
    "\n",
    "        if constraints:\n",
    "            g = ca.vertcat(*constraints)\n",
    "            self.lbg = np.concatenate(lbg)\n",
    "            self.ubg = np.concatenate(ubg)\n",
    "        else:\n",
    "            g = ca.MX()\n",
    "            self.lbg = np.array([])\n",
    "            self.ubg = np.array([])\n",
    "\n",
    "        self.x_sym = x\n",
    "        self.nlp = {'x': x, 'f': cost, 'g': g}\n",
    "        self.solver = ca.nlpsol('solver', 'sqpmethod', self.nlp, {'qpsol': 'qrqp', 'print_time': 0})\n",
    "\n",
    "    def solve(self, x_init):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        x_init = np.array(x_init).flatten()\n",
    "        self.x_init = x_init.copy()\n",
    "\n",
    "        sol = self.solver(x0=x_init, lbg=self.lbg, ubg=self.ubg)\n",
    "        self.x_end = np.array(sol['x'].full()).flatten()\n",
    "\n",
    "        print(f\"Total computation time: {time.time() - start_time} sec.\")\n",
    "\n",
    "        return self.x_end\n",
    "    \n",
    "    def plot_results(self):\n",
    "        x_max, x_min, y_max, y_min = 2.5, -2.5, 2.5, -2.5\n",
    "        x = np.linspace(x_min, x_max, 400)\n",
    "        y = np.linspace(y_min, y_max, 400)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                Z[i, j] = self.objective_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "\n",
    "        Z_log = np.log1p(Z)  # log(1 + Z), to highlight the difference\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "        # Contour of objective function\n",
    "        CS = ax.contourf(X, Y, Z_log, levels=100, cmap=cm.viridis, alpha=0.8)\n",
    "        cbar = plt.colorbar(CS, ax=ax)\n",
    "        cbar.set_label('log(1 + Cost)')\n",
    "\n",
    "        # Inequality constraint\n",
    "        if self.ineq_func is not None:\n",
    "            G_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    G_vals[i, j] = self.ineq_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, G_vals, levels=[0], colors='b', linewidths=2)\n",
    "            ax.plot([], [], color='blue', linewidth=2, label='Inequality constraint')\n",
    "            ax.contourf(X, Y, G_vals, levels=[-np.inf, 0], colors='blue', alpha=0.3)\n",
    "\n",
    "        # Equality constraint\n",
    "        if self.eq_func is not None:\n",
    "            H_vals = np.zeros_like(X)\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(X.shape[1]):\n",
    "                    H_vals[i, j] = self.eq_func(np.array([X[i, j], Y[i, j]])).full().flatten()[0]\n",
    "            ax.contour(X, Y, H_vals, levels=[0], colors='k', linewidths=2, linestyles='--')\n",
    "            ax.plot([], [], color='black', linestyle='--', linewidth=2, label='Equality constraint')\n",
    "\n",
    "        # Plot optimal point\n",
    "        if self.x_end is not None:\n",
    "            ax.plot(self.x_end[0], self.x_end[1], 'gs', markersize=10, label='Optimal solution from SQP solver', zorder=11)\n",
    "\n",
    "        # Plot known global minimum\n",
    "        if self.global_minima is not None:\n",
    "            ax.plot(self.global_minima[0], self.global_minima[1], '*', color='red', markersize=15, label='Global minima of unconstrained optimization')\n",
    "\n",
    "        ax.plot(self.x_init[0], self.x_init[1], color='darkorange', marker='o', markersize=8, label='Initial guess', zorder=11)\n",
    "\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.set_xlabel('$x_0$')\n",
    "        ax.set_ylabel('$x_1$')\n",
    "        ax.set_title(\"SQP (sqpmethod) Optimization Result\")\n",
    "        ax.grid(True)\n",
    "        ax.legend(loc='lower left')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad41d76",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "##### **Example 3.4: Using Built-in SQP Solver for NLP**\n",
    "\n",
    "1\\) Specify the objective function as follows;\n",
    "\n",
    "- Quadratic function: $f(\\boldsymbol{x}) = \\frac{1}{8} x_0^2 + \\frac{1}{2} x_1^2$\n",
    "\n",
    "2\\) Specify the nonlinear constraints as follows; \n",
    "\n",
    "- Equality constraint: None (can be considered as a special case of inequality constraint)  \n",
    "\n",
    "- Inequality constraint: $g(\\boldsymbol{x}) = {(x_0 - 1)}^2 + 3{(x_1 - 1.5)}^2 - 1$ (Ellipsoid)   \n",
    "\n",
    "3\\) Instantiate the class `SQPOptimizer` with pre-defined $f(\\boldsymbol{x})$, $g(\\boldsymbol{x})$ and $h(\\boldsymbol{x})$;\n",
    "\n",
    "4\\) Set the initial guess as $[1.5 \\quad 1.5]$ and call function `solve()` to solve the NLP problem;\n",
    "\n",
    "5\\) Call function `plot_results()` to visualize the results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e22dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ca.MX.sym('x', 2)\n",
    "\n",
    "# Objective: simple quadratic\n",
    "f = ca.Function(\"f\", [x], [0.5 * (x[0]**2 / 4 + x[1]**2)])\n",
    "# Inequality constraint: ellipsoid\n",
    "g = ca.Function(\"g\", [x], [(x[0] - 1)**2 + (x[1] - 1.5)**2 * 3 - 1])  # g(x) <= 0\n",
    "# Equality constraint: None\n",
    "h = None  \n",
    "\n",
    "sqp_solver = SQPOptimizer(\n",
    "    objective_func=f,\n",
    "    eq_func=h,\n",
    "    ineq_func=g,\n",
    "    global_minima=[0, 0]\n",
    ")\n",
    "\n",
    "x_init = np.array([1.5, 1.5])\n",
    "\n",
    "sol = sqp_solver.solve(x_init)\n",
    "sqp_solver.plot_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae29b44",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### **Conclusion**\n",
    "\n",
    "In this chapter, we discussed many importants aspects of solving various optimization problems. Through various examples and algorithmic components, we highlighted that the effectiveness of a solver is highly sensitive to:\n",
    "\n",
    "- How the problem is formulated (e.g., cost structure, constraints)\n",
    "\n",
    "- The choice of optimization algorithm\n",
    "\n",
    "- The tuning of solver parameters\n",
    "\n",
    "These aspects directly impact convergence speed, robustness, and solution quality.\n",
    "\n",
    "In particular, we introduced the Sequential Quadratic Programming (SQP) framework, which plays a central role in solving constrained nonlinear optimal control problems. SQP will reappear as the core optimization strategy in both:\n",
    "\n",
    "- Iterative Linear Quadratic Regulator (ILQR) in Chapter 4\n",
    "\n",
    "- nonlinear Model Predictive Control (NMPC) in Chapter 5\n",
    "\n",
    "These methods build upon the optimization foundations laid in this chapter to address increasingly complex and realistic control tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
