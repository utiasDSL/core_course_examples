{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd855d5a",
   "metadata": {},
   "source": [
    "### **Mountain Car Problem: Introduction**\n",
    "\n",
    "The mountain car problem is a classical control problem that illustrates the dynamics of a car moving on a profile. This problem is influenced by gravity, the profile's inclination, and an applied acceleration input, as depicted in the figure below. Our primary objective is to design a control policy using various methods (e.g. LQR, MPC, and RL) to drive the car from an initial state $x_0$ to a predefined terminal state $x_T$, all while being subject to constraints.\n",
    "\n",
    "![Figure 1: Illustration of a mountain car problem](../figure/MountainCarIllustration.png)\n",
    "\n",
    "#### **Variations of the Mountain Car Problem**\n",
    "\n",
    "The mountain car problem can be set up in different ways to study various aspects of this control problem and can be divided into the following categories:\n",
    "\n",
    "\n",
    "##### 1. **Type of Task**\n",
    "\n",
    "- **Terminal State Reaching**: The classic setting where the car must reach a target state (e.g., the hilltop) as quickly or efficiently as possible.  \n",
    "\n",
    "- **Stabilization**: The goal is to stabilize the car at a designated equilibrium point **(the focus of this Jupyter Notebook series)**.  \n",
    "\n",
    "- **Trajectory Tracking**: The car is required to follow a predefined trajectory over time.  \n",
    "\n",
    "- **Time-Optimal Control**: The focus is on minimizing the number of time steps to reach the target.  \n",
    "\n",
    "\n",
    "##### 2. **Type of Dynamics**\n",
    "\n",
    "- **Continuous-time Dynamics**: Systems whose states evolve continuously over time, typically modeled by differential equations such as $\\dot{x}(t)=f_c(x(t),u(t))$, where $x(t)$ and $u(t)$ are the the state and input at time $t$, respectively, and $f_c$ are the continuous-time system dynamics. The dynamic equations derived from first principles or Newton's laws are continuous-time dynamic equations.  \n",
    "\n",
    "- **Discrete-time Dynamics**: Systems whose states evolve at distinct time steps, typically modeled by difference equations such as $x_{k+1}=f(x_k,u_k)$, where $x_k$ and $u_k$ are the the state and input at step $k$, respectively, and $f$ are the discrete-time system dynamics. Due to the discrete nature of computer systems, we need to implement controllers in a discrete-time fashion.  \n",
    "\n",
    "- **Linear Dynamics**: the future behavior of the system depends linearly on its current state and input, typically expressed as $\\dot{x}=Ax+Bu$, Where $A$ is the system matrix and $B$ is the input matrix. Always used for simplified analysis or as a local approximation near equilibrium points. For example the car moving along a flat ground or a slope with constant inclination angle.  \n",
    "\n",
    "- **Nonlinear Dynamics**: the general case that captures the nonlinear evolution of the system dynamcis, typically expressed as $\\dot{x}=f(x,u)$. Especially introducing the gravitational effects and nonlinear terrain profiles, making the problem significantly harder to solve but also more realistic.  \n",
    "\n",
    "\n",
    "##### 3. **Type of State and Input**\n",
    "\n",
    "- **Continuous State / Input**: the state or input variables can take any value within a continuous range.\n",
    "\n",
    "- **Discrete State / Input**: the state or input variables can only take values from a countable set, often finite or indexed by integers. A general example of discrete state space together with discrete input space  is the Traveling Salesman Problem (TSP).\n",
    "\n",
    "- **Unconstrained State / Input**:  the state or input variables are free to take any value, which means $\\boldsymbol{x} \\in \\mathbb{R}^n$ and $\\boldsymbol{u} \\in \\mathbb{R}^m$\n",
    "\n",
    "- **Constrained State / Input**:  the state or input variables are restricted to lie within specified bounds or satisfy certain conditions, reflecting physical or actuator limits.\n",
    "\n",
    "\n",
    "These variations enable researchers and practitioners to explore a broad spectrum of control strategies, from classical methods (e.g., PID, LQR) to modern techniques (e.g., MPC, reinforcement learning), under diverse dynamics and objectives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f34a00",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "### **Chapter 1: Problem Definition and Dynamic Programming**\n",
    "\n",
    "\n",
    "In the first chapter, we will introduce the mountain car problem and demonstrate how to implement a Dynamic Progamming (DP)-based controller. We begin with implementing the mountain car environment (e.g., defining the slope and constraints), followed by defining the system dynamics and implementing the controller based on DP. The contents are summarized in the table below.  \n",
    "\n",
    "<table border=\"1\" style=\"border-collapse: collapse; text-align: center;\">\n",
    "  <!-- Title Row -->\n",
    "  <tr>\n",
    "    <th colspan=\"2\" style=\"text-align:center\">Content of Chapter 1 Exercise</th>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 1 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">Mountain Car Environment</td>\n",
    "    <td>Define mountian profile</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mountian profile to inclination angle</td>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 2 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"3\">System Dynamics</td>\n",
    "    <td>Symbolic expression of system dynamics</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Linearization of system dynamics</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Discretization of system dynamics</td>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 3 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">Dynamic Programming (continuous input)</td>\n",
    "    <td>DPA for continuous input case</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>simulation and visualization</td>\n",
    "  </tr>\n",
    "\n",
    "  <!-- Row group 4 -->\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">Dynamic Programming (discrete input)</td>\n",
    "    <td>DPA for discrete input case</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Simulation and visualization</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "First, we need to set up our Python environment and import relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all related classes from the predefined repo\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import casadi as ca\n",
    "from __future__ import annotations\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.env import *\n",
    "from utils.simulator import *\n",
    "from ex1_DP.dp_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cad49",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### **Part (a): Mountain Car Environment**\n",
    "\n",
    "\n",
    "In this part, we set up the environment for the mountain car problem. The environment consists of defining the terrain profile, mapping the terrain to inclination angles, and specifying task parameters for the controller. The steps include creating a mathematical representation of the terrain, deriving the relationship between the slope and inclination angle, and finally specifying parameters such as the initial state, terminal state, and constraints to uniquely define a control task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3f0ea",
   "metadata": {},
   "source": [
    "**Step 1: The Mountain Profile $h(p)$**\n",
    "\n",
    "The mountain profile describes the height $h$ with reference to horizontal position $p$. As mentioned above, there are different choices for the mountain profile in the mountain car problem. Here we specifically designed 4 cases (as shown in the figure below), where we have 2 linear cases and 2 nonlinear cases:\n",
    "\n",
    " - Case 1: zero slope (linear system);\n",
    " \n",
    " - Case 2: constant slope (linear system);\n",
    " \n",
    " - Case 3: varying slope for small disturbance (nonlinear system);\n",
    " \n",
    " - Case 4: varying slope and underactuated system (nonlinear system).\n",
    "\n",
    "*Note that: The underactuated case refers to a scenario where the input is limited and may be insufficient to generate enough force to climb uphill directly.*\n",
    "\n",
    "![Figure 2: Different mountain profile choices](../figure/MountainProfileCases.png)\n",
    "\n",
    "The analytical expressions of the profiles are:\n",
    "\n",
    " - Case 1: $\\quad h(p) = c,$\n",
    "\n",
    " - Case 2: $\\quad h(p) = \\frac{\\pi}{18} \\cdot p,$\n",
    "\n",
    " - Case 3: $\\quad h(p) = 0.1 \\cdot \\cos(18 p)$\n",
    "\n",
    " - Case 4: $\\quad h(p) = \\begin{cases} \\sin(3 p), & p \\in [- \\frac{\\pi}{2}, \\frac{\\pi}{6}] \\\\ 1, & p \\in (-\\infty, -\\frac{\\pi}{2}) \\cup (\\frac{\\pi}{6}, \\infty) \\end{cases}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd2044-05f4-432e-8fce-ff8bb2b45e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the profile of mountain h(p)\n",
    "#  - argument: 1) p: CasAdi symbolic expression `p`\n",
    "#              2) case: integer value to choose the mountain's profile\n",
    "#  - return: value of `h`\n",
    "\n",
    "def h(p, case):\n",
    "    \n",
    "    # zero slope\n",
    "    if case == 1:\n",
    "        h = 0\n",
    "   \n",
    "    # constant slope\n",
    "    elif case == 2: \n",
    "        h = (ca.pi * p) / 18\n",
    "    \n",
    "    # varying slope\n",
    "    elif case == 3: \n",
    "\n",
    "        h = 0.1 * ca.cos(18 * p)\n",
    "\n",
    "    # varying slope for underactated case\n",
    "    elif case == 4: \n",
    "        h_center = ca.sin(3 * p)\n",
    "        h_flat = 1\n",
    "\n",
    "        condition_left = p <= -ca.pi/2\n",
    "        condition_right = p >= ca.pi/6\n",
    "\n",
    "        h = ca.if_else(condition_left, h_flat, ca.if_else(condition_right, h_flat, h_center))\n",
    "\n",
    "    return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16e26a",
   "metadata": {},
   "source": [
    "**Step 2: Mapping From Profile $h(p)$ to Inclination Angle $\\theta(p)$**\n",
    "\n",
    "- Transformation function from $h$ to $\\theta$:\n",
    "\n",
    "   \\begin{align*}\n",
    "     \\theta = \\arctan\\left(\\frac{dh}{dp}\\right)\n",
    "   \\end{align*}\n",
    "\n",
    "- Hint: \n",
    "\n",
    "  1. Using the CasAdi symbolic expression as the input, we can directly solve the gradient $\\frac{dh}{dp}$ with method `ca.jacobian(h, p)`; \n",
    "\n",
    "  2. The angle $\\theta$ is defined in radian;  \n",
    "\n",
    "- Notice: If the function $h(p)$ is defined numerically rather than symbolically, we can use **numerical differentiation** to approximate $\\frac{dh}{dp}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739781d4-000a-4138-8363-b1f72f332893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate inclination angle theta(p) based on terrain profile h(p)\n",
    "#  - argument: CasAdi symbolic expression `h_func`\n",
    "#  - return: CasAdi symbolic expression `theta(p)`\n",
    "\n",
    "def symbolic_theta(h_func):\n",
    "\n",
    "    p = ca.SX.sym(\"p\")\n",
    "\n",
    "    h = h_func(p) \n",
    "    dh_dp = ca.jacobian(h, p)\n",
    "    theta = ca.atan(dh_dp)\n",
    "    \n",
    "    return ca.Function(\"theta\", [p], [theta])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf273e4",
   "metadata": {},
   "source": [
    "**Step 3: Environment Parameters and Control Task**\n",
    "\n",
    "- Task: start from given initial position $p_0$, to reach a given target position $p_T$ (Stabilization)\n",
    "\n",
    "- You may use the pre-defined method `test_env()` to check the slope $h(p)$ and and the inclination angle $\\theta(p)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d782c95-de15-49ec-a999-37ee410d8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 2 # 1 / 2\n",
    "\n",
    "# Define the initial / target state\n",
    "initial_position = -0.5\n",
    "initial_velocity = 0.0\n",
    "target_position = 0.5\n",
    "target_velocity = 0.0\n",
    "\n",
    "# Define the state / input constraints\n",
    "state_lbs = None\n",
    "state_ubs = None\n",
    "input_lbs = None\n",
    "input_ubs = None\n",
    "\n",
    "# Instantiate class 'Env'\n",
    "#  - argument: 1) `case`: n in [1, 2], type: int\n",
    "#              2) `initial state`: x_0 = [p_0, v_0] ^ T, type: np.array\n",
    "#              3) `terminal state`: x_T = [p_T, v_T] ^ T, type: np.array\n",
    "#              4) `h`: mountain profile w.r.t. cases (defined in step 1), type: function\n",
    "#              5) `symbolic_theta`: CasADi symbolic expression of inclination angle (defined in step 2), type: ca.Function\n",
    "#              6) constraints on states and inputs:\n",
    "#                  - `state_lbs`: lower limit of state, type: np.array or None (if no related limit)\n",
    "#                  - `state_ubs`: upper limit of state, type: np.array or None (if no related limit)\n",
    "#                  - `input_lbs`: lower limit of input, type: np.array or None (if no related limit)\n",
    "#                  - `input_ubs`: upper limit of input, type: float or None (if no related limit)\n",
    "env = Env(case=case, \n",
    "          init_state=np.array([initial_position, initial_velocity]), \n",
    "          target_state=np.array([target_position, target_velocity]), \n",
    "          symbolic_h_mean_ext_case=h, \n",
    "          symbolic_theta_ext=symbolic_theta, \n",
    "          state_lbs=state_lbs, \n",
    "          state_ubs=state_ubs, \n",
    "          input_lbs=input_lbs, \n",
    "          input_ubs=input_ubs)\n",
    "\n",
    "# Results visualisation\n",
    "env.test_env() #  shape of slope (left side) and theta curve (right side) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e492c8",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### **Part (b): System Dynamics**\n",
    "\n",
    "\n",
    "In the previous section, we defined the mountain car environment, including the terrain profile and the mapping from the profile to the inclination angle. In this section, we define a class that describes the system dynamics of the mountain car on this mountain profile. This includes specifying the state and input vectors, constructing the dynamics equations using symbolic computation in CasADi, and linearization and discretization.\n",
    "\n",
    "Consider the following set of parameter that describe the motion of the mountain car:\n",
    "\n",
    "   - the horizontal position of the car $p$;\n",
    "   - the driving force $F_u=mu$, where $u$ is the acceleration supplied by engine, and is parallel to the mountain surface.\n",
    "\n",
    "The following figure illustrates the free-body diagram of the mountain car, where its motion is influenced by the driving force, gravitational force, and the normal force.\n",
    "\n",
    "![Figure 3: FBD of mountaincar problem](../figure/MountaincarFBD.png)\n",
    "\n",
    "By applying Newton's second law along the horizontal direction, the equation of motion can be expressed as:\n",
    "\n",
    "$$m\\ddot{p} = (mu-mg\\sin(\\theta))\\cos(\\theta),$$\n",
    "\n",
    "\n",
    "where $m$ represents the mass of the car, $g$ is the acceleration due to gravity, $\\theta$ denotes the inclination angle of the slope, and $F_N = mg \\cos(\\theta)$. This equation can be reformulated into a system of first-order differential equations as follows:\n",
    "$$\n",
    "  \\left\\{\n",
    "  \\begin{aligned}\n",
    "  \\dot{p} &= v, \\\\\n",
    "  \\dot{v} &= -g\\sin(\\theta)\\cos(\\theta)+u\\cos(\\theta),\n",
    "  \\end{aligned}\n",
    "  \\right.\n",
    "$$\n",
    "\n",
    "To facilitate analysis and control design, the system dynamics can be expressed in a state-space representation:\n",
    "\n",
    "   - state vector $\\boldsymbol{x} = [p, v]^T$\n",
    "   - input vector $u$\n",
    "   - system dynamics:\n",
    "   \\begin{align*}\n",
    "     \\begin{bmatrix} \\dot{p} \\\\ \\dot{v} \\end{bmatrix} = \\begin{bmatrix} v \\\\ - g \\sin(\\theta) \\cos(\\theta) \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\cos(\\theta)  \\end{bmatrix} u\n",
    "   \\end{align*}\n",
    "\n",
    "*Note that: Dynamics equations derived from first principles, such as Newton's laws, are inherently continuous in time and generally nonlinear. To enhance computational efficiency, it is common practice to linearize and discretize these equations as shown in steps 2 and 3.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c51f4",
   "metadata": {},
   "source": [
    "**Step 1: Setup the Mountain Car Dynamics**\n",
    "\n",
    "- Hints about defining CasADi symbolic expression: \n",
    "\n",
    "  1. The variables used for symbolic computation should be declared in datatype `ca.SX` or `ca.MX`;\n",
    "\n",
    "  2. To combine several variables into a vector, use `ca.vertcat(a, b, ...)`;\n",
    "\n",
    "  3. To define a CasADi function, use `ca.Function(\"function_name\", [input1, input2, ...], [output])`;\n",
    "  \n",
    "  4. To call a CasADi function, use `function_name(input1, input2, ...))`;\n",
    "\n",
    "- Supplementary materials:\n",
    "  \n",
    "  1. Introduction to symbolic modeling in CasADi: https://web.casadi.org/docs/#document-symbolic\n",
    "  \n",
    "  2. CasADi's Python API: https://web.casadi.org/python-api/\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a15705-214e-4504-9624-fdbe406f6826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dynamics of 1d mountain car\n",
    "#  - arguments: `theta_function`: CasADi symbolic function of inclination angle `theta_function`, type: ca.Function\n",
    "#  - return: `dynamics_function`: CasADi symbolic function of dynamics, type: ca.Function\n",
    "\n",
    "def setup_dynamics(theta_function):\n",
    "\n",
    "    p = ca.SX.sym(\"p\")\n",
    "    v = ca.SX.sym(\"v\")\n",
    "    u = ca.SX.sym(\"u\")\n",
    "    \n",
    "    Gravity = 9.81\n",
    "\n",
    "    theta = theta_function(p)\n",
    "\n",
    "    # Expression of dynamics\n",
    "    dpdt = v\n",
    "    dvdt = u * ca.cos(theta) - Gravity * ca.sin(theta) * ca.cos(theta)\n",
    "    \n",
    "    state = ca.vertcat(p, v)\n",
    "    input = ca.vertcat(u)\n",
    "    rhs = ca.vertcat(dpdt, dvdt)\n",
    "\n",
    "    return ca.Function(\"dynamics_function\", [state, input], [rhs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3360ea",
   "metadata": {},
   "source": [
    "\n",
    "**Step 2: Linearizing the System Dynamics**\n",
    "\n",
    "The derived equations of motion above are typically written in the form of $\\dot{\\boldsymbol{x}} = \\boldsymbol{f}_c (\\boldsymbol{x}, \\boldsymbol{u})$, where $\\boldsymbol{x}$ is the state, $\\boldsymbol{u}$ is the input, and $\\boldsymbol{f}_c: n \\times m \\to n$ denote the mapping from state and input to the derivatives of the state. Generally speaking, the function $\\boldsymbol{f}_c$ is nonlinear, which means the evolution of the system dynamics cannot be captured by simple linear algebraic operations such as matrix multiplication. This significantly increases the complexity of solving the problem. To simplify the problem, especially in the context of local analysis or model-based control (e.g., LQR, MPC), it is a common practice to **linearize** the nonlinear dynamics around a given **operating point**.\n",
    "\n",
    "\n",
    "Assume we are interested in the behavior of the system near some nominal point $(\\boldsymbol{x}_0, \\boldsymbol{u}_0)$. We perform a **first-order Taylor expansion** of $\\boldsymbol{f}_c(\\boldsymbol{x}, \\boldsymbol{u})$ around this point:  \n",
    "\n",
    "$$\n",
    "\\boldsymbol{f}_c(\\boldsymbol{x}, \\boldsymbol{u}) \\approx \\boldsymbol{f}_c(\\boldsymbol{x}_0, \\boldsymbol{u}_0) + \n",
    "\\left. \\frac{\\partial \\boldsymbol{f}_c}{\\partial \\boldsymbol{x}} \\right|_{(\\boldsymbol{x}_0, \\boldsymbol{u}_0)} \n",
    "(\\boldsymbol{x} - \\boldsymbol{x}_0) +\n",
    "\\left. \\frac{\\partial \\boldsymbol{f}_c}{\\partial \\boldsymbol{u}} \\right|_{(\\boldsymbol{x}_0, \\boldsymbol{u}_0)} \n",
    "(\\boldsymbol{u} - \\boldsymbol{u}_0).\n",
    "$$\n",
    "\n",
    "We define the **perturbation variables** as:  \n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\overline{x}} = \\boldsymbol{x} - \\boldsymbol{x}_0, \\quad\n",
    "\\boldsymbol{\\overline{u}} = \\boldsymbol{u} - \\boldsymbol{u}_0.\n",
    "$$\n",
    "\n",
    "Substitute them into the expansion:  \n",
    "\n",
    "$$\n",
    "\\dot{\\boldsymbol{x}} - \\boldsymbol{f}_c(\\boldsymbol{x}_0, \\boldsymbol{u}_0) \\approx \n",
    "\\left. \\frac{\\partial \\boldsymbol{f}_c}{\\partial \\boldsymbol{x}} \\right|_{(\\boldsymbol{x}_0, \\boldsymbol{u}_0)} \\boldsymbol{\\overline{x}} + \\left. \\frac{\\partial \\boldsymbol{f}_c}{\\partial \\boldsymbol{u}} \\right|_{(\\boldsymbol{x}_0, \\boldsymbol{u}_0)} \\boldsymbol{\\overline{u}}.\n",
    "$$\n",
    "\n",
    "Since $\\dot{\\boldsymbol{x}}_0 = \\boldsymbol{f}_c(\\boldsymbol{x}_0, \\boldsymbol{u}_0)$ and $\\dot{\\boldsymbol{\\overline{x}}} = \\dot{\\boldsymbol{x}} - \\dot{\\boldsymbol{x}}_0$, the **linearized system dynamics** around the nominal point become:  \n",
    "\n",
    "$$\n",
    "\\dot{\\boldsymbol{\\overline{x}}} = \\boldsymbol{A}_c \\boldsymbol{\\overline{x}} + \\boldsymbol{B}_c \\boldsymbol{\\overline{u}},\n",
    "$$\n",
    "\n",
    "with state matrix $\\boldsymbol{A}_c$ and input matrix $\\boldsymbol{B}_c$ defined as:  \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_c = \\left. \\frac{\\partial \\boldsymbol{f}_c}{\\partial \\boldsymbol{x}} \\right|_{(\\boldsymbol{x}_0, \\boldsymbol{u}_0)}, \\quad\n",
    "\\boldsymbol{B}_c = \\left. \\frac{\\partial \\boldsymbol{f}_c}{\\partial \\boldsymbol{u}} \\right|_{(\\boldsymbol{x}_0, \\boldsymbol{u}_0)}.\n",
    "$$\n",
    "\n",
    "This linearized model accurately approximates the original nonlinear system **locally**, i.e., within a small neighborhood around the point $(\\boldsymbol{x}_0, \\boldsymbol{u}_0)$, and forms the basis for many powerful linear control design techniques.\n",
    "\n",
    "*Note that: To simplify notation and avoid ambiguity, we will omit the overbars on variables $\\boldsymbol{\\overline{x}}$ and $\\boldsymbol{\\overline{u}}$ in the following discussions of continuous-time system dynamics. This simplification is intended to streamline expressions without loss of clarity.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4126e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearization_external(\n",
    "    self,\n",
    "    current_state: np.ndarray, \n",
    "    current_input: np.ndarray, \n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute symbolic Jacobians A(x,u) & B(x,u) and state / input matrix A & B of the system dynamics.\n",
    "    \"\"\"\n",
    "\n",
    "    f = self.dynamics_function(self.states, self.inputs)\n",
    "    A_c_sym = ca.jacobian(f, self.states)\n",
    "    B_c_sym = ca.jacobian(f, self.inputs)\n",
    "\n",
    "    self.A_c_func = ca.Function(\"A_func\", [self.states, self.inputs], [A_c_sym])\n",
    "    self.B_c_func = ca.Function(\"B_func\", [self.states, self.inputs], [B_c_sym])\n",
    "\n",
    "    A_c = np.array(self.A_c_func(current_state, current_input))\n",
    "    B_c = np.array(self.B_c_func(current_state, current_input))\n",
    "\n",
    "    return A_c, B_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce05aa",
   "metadata": {},
   "source": [
    "**Step 3: Discretization of the system dynamics**\n",
    "\n",
    "After linearizing the continuous-time nonlinear system, we obtain a system in the form:\n",
    "\n",
    "$$\n",
    "\\dot{\\boldsymbol{x}}(t) = \\boldsymbol{A_c} \\boldsymbol{x}(t) + \\boldsymbol{B_c} \\boldsymbol{u}(t).\n",
    "$$\n",
    "\n",
    "Due to the inherently discrete nature of modern computing and control systems, our goal is to convert this into a discrete-time system of the form:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_{k+1} = \\boldsymbol{A_d} \\boldsymbol{x}_k + \\boldsymbol{B_d} \\boldsymbol{u}_k.\n",
    "$$\n",
    "\n",
    "We assume that during each sampling interval $[k\\Delta t, (k+1)\\Delta t)$, the input $\\boldsymbol{u}(t)$ remains **constant**. This as also known as the **Zero-order hold (ZOH)**, which is a mathematical model used to describe signal reconstruction in traditional digital-to-analog converters (DACs). The exact discretization under ZOH is:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A_d} = e^{\\boldsymbol{A_c} \\Delta t}, \\quad\n",
    "\\boldsymbol{B_d} = \\left( \\int_0^{\\Delta t} e^{\\boldsymbol{A_c} \\tau} d\\tau \\right) \\boldsymbol{B_c}.\n",
    "$$\n",
    "\n",
    "Instead of computing $\\boldsymbol{B_d}$ using numerical integration, we can use the **augmented matrix exponential** trick:\n",
    "\n",
    "$$\n",
    "\\exp \\left(\n",
    "\\begin{bmatrix}\n",
    "\\boldsymbol{A_c} & \\boldsymbol{B_c} \\\\\n",
    "0 & 0\n",
    "\\end{bmatrix} \\Delta t \n",
    "\\right)\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\boldsymbol{A_d} & \\boldsymbol{B_d} \\\\\n",
    "0 & I\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "*This can be efficiently achieved using `scipy.signal.cont2discrete((A, B, C, D), dt)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f775f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretization_external(\n",
    "    self,\n",
    "    A_c: np.ndarray,\n",
    "    B_c: np.ndarray,\n",
    "    dt: float\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Discretize continuous-time linear system x_dot = A_c x + B_c u\n",
    "    using matrix exponential method (Zero-Order Hold).\n",
    "\n",
    "    Returns:\n",
    "        A_d, B_d: Discrete-time system matrices\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct augmented matrix\n",
    "    aug_matrix = np.zeros((self.dim_states + self.dim_inputs, self.dim_states + self.dim_inputs))\n",
    "    aug_matrix[:self.dim_states, :self.dim_states] = A_c\n",
    "    aug_matrix[:self.dim_states, self.dim_states:] = B_c\n",
    "\n",
    "    # Compute matrix exponential\n",
    "    exp_matrix = scipy.linalg.expm(aug_matrix * dt)\n",
    "\n",
    "    # Extract A_d and B_d\n",
    "    A_d = exp_matrix[:self.dim_states, :self.dim_states]\n",
    "    B_d = exp_matrix[:self.dim_states, self.dim_states:]\n",
    "\n",
    "    return A_d, B_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8fd4bc",
   "metadata": {},
   "source": [
    "**Step 4: Arguments for Class 'Dynamics' and Instantiate the Class**\n",
    "  \n",
    "- Steps: \n",
    "\n",
    "  1) Bind the defined linearization and discretization functions to the class `Dynamics`, which will be called by other methods;\n",
    "\n",
    "  2) Specify the arguments and instantiate the class `Dynamics`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d224d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the states and input as symbolic variables\n",
    "state_names = [\"p\", \"v\"]\n",
    "input_names = [\"u\"]\n",
    "\n",
    "# Bind the defined algorithm to the corresponding class, will be automatically called by other methods\n",
    "Dynamics.linearization = linearization_external\n",
    "Dynamics.discretization = discretization_external\n",
    "\n",
    "# Instantiate class 'Dynamics'\n",
    "#  - arguments: 1) `env`: object of class `Env`, type: Env\n",
    "#              2) `state_names`: names of state variables, type: list[str]\n",
    "#              3) `input_names`: names of input variables, type: list[str]\n",
    "#              4) `setup_dynamics`: setup function for system dynamics defined in the last step, type: function\n",
    "dynamics = Dynamics(env=env, \n",
    "                    state_names=state_names, \n",
    "                    input_names=input_names, \n",
    "                    setup_dynamics=setup_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993c0d4",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### **Part (C): Implement the Dynamic Programming-based Controller**\n",
    "\n",
    "**Problem Formulation:**\n",
    "\n",
    "$$\n",
    "J_k(\\boldsymbol{x_k}) = \\min_{u_{k|k}, \\ldots, u_{k+N-1|k}} \n",
    "\\sum_{i=0}^{N-1} u_{k+i|k} ^T \\boldsymbol{R} u_{k+i|k}\n",
    "+ \\left( \\boldsymbol{x_{k+N|k}} - \\boldsymbol{x_T} \\right)^T \\boldsymbol{Q_f} \\left( \\boldsymbol{x_{k+N|k}} - \\boldsymbol{x_T} \\right)\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x_{k+i+1|k}} = \\boldsymbol{A_{d}} \\boldsymbol{x_{k+i|k}} + \\boldsymbol{B_{d}}u_{k+i|k}, \\quad \\forall i \\in \\{0, \\ldots, N-1\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x_{k|k}} = \\boldsymbol{x_{k}} \\,,\n",
    "$$\n",
    "where $\\boldsymbol{x_{k+i|k}}$ indicates state $x$ at time step $k + i$ predicted at time step $k$. \n",
    "\n",
    "*Note: to start with a simpler case and illustrate the fundamental idea of dynamic programming, we temporarily ignore a penalty on the state and are not considering constraints. In the next section, we will consider the case of discrete inputs and demonstrate how to solve it accordingly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b0ddd",
   "metadata": {},
   "source": [
    "**Problem Solving:**\n",
    "\n",
    "At the terminal step $ k = N $, the cost-to-go is initialized using the terminal cost function:\n",
    "\n",
    "$$\n",
    "J_N(\\boldsymbol{x}_N) = (\\boldsymbol{x}_N - \\boldsymbol{x}_T)^T Q_f (\\boldsymbol{x}_N - \\boldsymbol{x}_T)\n",
    "$$\n",
    "\n",
    "Starting from this terminal cost, we perform a **backward recursion** from $ k = N-1 $ down to $ k = 0 $ to compute the **optimal control policy** $ \\mu_k(\\boldsymbol{x}_k) $ and the corresponding **cost-to-go function** $ J_k(\\boldsymbol{x}_k) $ at each step, based on the future cost $ J_{k+1}(\\boldsymbol{x}_{k+1}) $:\n",
    "\n",
    "- **Compute total cost-to-go from this step:**\n",
    "\n",
    "   $$\n",
    "   J_k(\\boldsymbol{x}_{k}) = u_k^\\top R u_k + J_{k+1}(\\boldsymbol{x}_{k+1})\n",
    "   $$\n",
    "\n",
    "   Here, $ J_{k+1} $ is a symbolic function of the predicted next state.\n",
    "\n",
    "- **Substitute $ \\boldsymbol{x}_{k+1} $ into $ J_{k+1} $ using linear system dynamics:**\n",
    "\n",
    "   $$\n",
    "   J_{k+1}(\\boldsymbol{x}_{k+1}) \\leftarrow J_{k+1}(\\boldsymbol{A}_d \\boldsymbol{x}_k + \\boldsymbol{B}_d u_k)\n",
    "   $$\n",
    "\n",
    "- **Solve for the optimal input $ u_k^* $ by minimizing the total cost:**\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial J_k}{\\partial u_k} = 0 \\quad \\Rightarrow \\quad u_k^* = \\mu_k(\\boldsymbol{x}_k)\n",
    "   $$\n",
    "\n",
    "- **Plug $ u_k^* $ back into the cost to get the updated cost-to-go:**\n",
    "\n",
    "   $$\n",
    "   J_k^*(\\boldsymbol{x}_k) = J_k|_{u_k = \\mu_k(\\boldsymbol{x}_k)}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362f5f0",
   "metadata": {},
   "source": [
    "**Step 1: implement the DP algorithm**  \n",
    "\n",
    "In this implementation, we use the `SymPy` symbolic computation library to construct a dynamic programming (DP) solution analytically. Symbolic methods allow us to derive explicit expressions for the control policy and cost-to-go function, which can help deepen our understanding of how DP works.\n",
    "\n",
    "1) **Define symbolic states and control inputs**  \n",
    "\n",
    "   We use `sympy.symbols()` to define symbolic variables for the state (e.g., position $ p $ and velocity $ v $) and the control input $ u $ at each time step.\n",
    "\n",
    "2) **Define weight matrices**  \n",
    "\n",
    "   The cost function weights $\\boldsymbol{R}$ and $\\boldsymbol{Q}_f$ are converted to SymPy matrix types to support symbolic operations.\n",
    "\n",
    "3) **Initialize the recursive cost matrix with terminal costs**  \n",
    "\n",
    "   The terminal cost is evaluated symbolically as $J_N(\\boldsymbol{x}_N) = (\\boldsymbol{x}_N - \\boldsymbol{x}_T)^T Q_f (\\boldsymbol{x}_N - \\boldsymbol{x}_T)$\n",
    "\n",
    "4) **Backward recursion using Bellman's principle**  \n",
    "\n",
    "   We loop backward from $k=N−1$ to $0$, computing the optimal control $\\mu_k(\\boldsymbol{x}_k)$ and the cost-to-go function $J_k^*(\\boldsymbol{x}_k)$ at each step. The total cost is defined symbolically, differentiated with respect to the control input, and analytically minimized using `sympy.solve()`:\n",
    "\n",
    "5) **Store the symbolic policy and cost functions**  \n",
    "\n",
    "   The resulting symbolic expressions for $\\mu_k(\\boldsymbol{x}_k)$ and $J_k^*(\\boldsymbol{x}_k)$ are stored in lists. These expressions can be later used for evaluation or substitution, \n",
    "\n",
    "*Note that: While the weight matrices $\\boldsymbol{R}$ and $\\boldsymbol{Q}_f$ can also be parameterized to derive more general control policies, this approach leads to increasingly nested symbolic expressions during the backward recursion process. As a result, the computational complexity grows exponentially with the number of iterations. To enhance computational efficiency, we choose to specify the weight matrices with concrete numerical values.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58badd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_external(self) -> None:\n",
    "\n",
    "    # Create symbolic states and inputs\n",
    "    self.x_sym = [sp.Matrix(sp.symbols(f'p_{k} v_{k}')) for k in range(self.N + 1)]\n",
    "    self.u_sym = [sp.Symbol(f'u_{k}') for k in range(self.N)]\n",
    "\n",
    "    # Convert numpy weight matrices to sympy matrices\n",
    "    self.R_sym = sp.Float(self.R)\n",
    "    self.Qf_sym = sp.Matrix(self.Qf)\n",
    "\n",
    "    # Convert numpy reference state to sympy array\n",
    "    self.x_ref_sym = sp.Matrix(self.target_state) \n",
    "\n",
    "    # Make a copy\n",
    "    J, mu = self.J_sym, self.mu_sym\n",
    "\n",
    "    # Terminal cost: J_N = (x_N - x_ref)^T Qf (x_N - x_ref)\n",
    "    err_N = self.x_sym[self.N] - self.x_ref_sym\n",
    "    J[self.N] = (err_N.T * self.Qf_sym * err_N)[0, 0]\n",
    "    \n",
    "    # Bellman recursion\n",
    "    for k in reversed(range(self.N)):\n",
    "        \n",
    "        # x_{k+1} = A x_k + B u_k\n",
    "        x_next = self.Ad * self.x_sym[k] + self.Bd * self.u_sym[k]\n",
    "\n",
    "        # Cost at step k: u_k^T R u_k + J_{k+1}(x_{k+1})\n",
    "        stage_cost = self.R_sym * self.u_sym[k]**2\n",
    "        J_kplus1_sub = J[k + 1].subs({self.x_sym[k + 1][i]: x_next[i] for i in range(2)})\n",
    "\n",
    "        total_cost = stage_cost + J_kplus1_sub\n",
    "\n",
    "        # Derivative w.r.t u_k\n",
    "        dJ_du = sp.diff(total_cost, self.u_sym[k])\n",
    "        u_star = sp.solve(dJ_du, self.u_sym[k])[0]\n",
    "        mu[k] = sp.simplify(u_star)\n",
    "\n",
    "        # Plug u_k* back into cost to get J_k\n",
    "        cost_k_opt = total_cost.subs(self.u_sym[k], u_star)\n",
    "        J[k] = sp.simplify(cost_k_opt)\n",
    "    \n",
    "    # Log the symbolic expressions back\n",
    "    self.J_sym = J\n",
    "    self.mu_sym = mu\n",
    "\n",
    "    if self.verbose:\n",
    "        print(f\"Dynamic Programming policy with input constraints computed.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a437f8d",
   "metadata": {},
   "source": [
    "**Step 2: bind the defined cost functions and DP algorithm to the class `DPController`**  \n",
    "\n",
    "- Steps: \n",
    "\n",
    "  1) Bind the defined setup function for DP algorithm `setup_external()` to class `DPController`, it will be automatically called by constructor;\n",
    "\n",
    "  2) Specify the arguments and instantiate the class `DPController`; \n",
    "\n",
    "  3) Call function `print_solution()` to show the DP policies;\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the defined DP algorithm to the corresponding class, will be automatically called by constructor\n",
    "DPController.setup = setup_external\n",
    "\n",
    "# Define control frequency of controller and time length of simulation\n",
    "freq = 10\n",
    "t_terminal = 10 # time length of simulation\n",
    "horizon = freq * t_terminal \n",
    "\n",
    "# Define weight matrix in stage and terminal cost\n",
    "Q = np.diag([1, 1])\n",
    "R = np.array([[0.1]])\n",
    "Qf = Q\n",
    "\n",
    "# Instantiate the DP controller class\n",
    "#  - arguments: 1) `env`: object of class `Env`, type\n",
    "#               2) `dynamics`: object of class `Dynamics`,\n",
    "#               3) weight matrices in cost functions:\n",
    "#                   - `Q`: weight matrix for current state $x_k$ in stage cost $J_s$, type: np.array\n",
    "#                   - `R`: weight matrix for current input $u_k$ in stage cost $J_s$, type: np.array\n",
    "#                   - `Q_f`: weight matrix for terminal state $x_N$ in terminal cost $J_f$, type: np.array\n",
    "#               4) `freq`: control frequency $f$ , type: int\n",
    "#               5) `horizon`: number of discretized time intervals (i.e. shooting nodes - 1) $N = t_f \\times f$, type: int\n",
    "controller_dp = DPController(env, dynamics, Q, R, Qf, freq, Horizon=horizon)\n",
    "\n",
    "# Show the symbolic expression of the policies\n",
    "controller_dp.print_solution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cca18e",
   "metadata": {},
   "source": [
    "**Step 3: run the simulation to see the performance of controller**  \n",
    "\n",
    "- Steps: \n",
    "\n",
    "  1) Instantiate the class `Simulator` and run function `run_simulation()` to generate the simulated state- and input-trajectory;\n",
    "\n",
    "  2) Instantiate the class `Visualizer`, run function `display_final_results()` and `display_animation()` to show the simulations;\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077045b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the simulator, and then run the simulation\n",
    "simulator_dp = Simulator(dynamics, controller_dp, env, 1/freq, t_terminal)\n",
    "simulator_dp.run_simulation()\n",
    "\n",
    "# Instantiate the visualizer, and display the plottings and animation\n",
    "visualizer_dp = Visualizer(simulator_dp)\n",
    "visualizer_dp.display_plots()\n",
    "visualizer_dp.display_animation()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51bce7c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### **Part (d): Implement the Dynamic Programming-based Controller with bang-bang input**\n",
    "\n",
    "\n",
    "As introduced at the beginning, optimal control problems come in many variations. The control inputs can be either continuous or discrete, and the problems may involve constraints or be unconstrained. In this section, we extend our symbolic DP implementation to handle **discrete-valued control inputs**, also known as **bang-bang control**. Unlike the previous continuous-input case, where the optimal control input was computed by analytically minimizing the cost function using calculus (first-order optimality conditions), here we **explicitly enumerate** all possible control actions (in this case: $ u_k \\in \\{-0.5, 0.5\\} $) and choose the one with the **lowest resulting cost**. The differences comparing with the previous continuous input DP are summarized as follows:\n",
    "\n",
    "| Feature | Continuous Input DP | Discrete (Bang-bang) DP |\n",
    "|--------|----------------------|--------------------------|\n",
    "| Control set | Continuous (e.g., $ u \\in \\mathbb{R} $) | Discrete ($ u \\in \\{-0.5, 0.5\\} $) |\n",
    "| Optimal input | Solved symbolically via derivative $ \\frac{dJ}{du} = 0 $ | Evaluated explicitly for each candidate input |\n",
    "| Policy format | Symbolic expression $ \\mu_k(x_k) $ | Symbolic piecewise function from enumeration |\n",
    "| Use case | Smooth unconstrained systems | Input-limited systems (e.g., switched systems) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281900d",
   "metadata": {},
   "source": [
    "**Problem Formulation:**\n",
    "\n",
    "$$\n",
    "J_k(\\boldsymbol{x_k}) = \\min_{u_{k|k}, \\ldots, u_{k+N-1|k}} \n",
    "\\sum_{i=0}^{N-1} u_{k+i|k} ^T \\boldsymbol{R} u_{k+i|k}\n",
    "+ \\left( \\boldsymbol{x_{k+N|k}} - \\boldsymbol{x_T} \\right)^T \\boldsymbol{Q_f} \\left( \\boldsymbol{x_{k+N|k}} - \\boldsymbol{x_T} \\right)\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x_{k+i+1|k}} = \\boldsymbol{A_{d}} \\boldsymbol{x_{k+i|k}} + \\boldsymbol{B_{d}}u_{k+i|k}, \\quad \\forall i \\in \\{0, \\ldots, N-1\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boxed{u \\in \\{-0.5, 0.5\\}, \\quad \\forall i \\in \\{0, \\ldots, N-1\\}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x_{k|k}} = \\boldsymbol{x_{k}}\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5868b6",
   "metadata": {},
   "source": [
    "**Problem Solving:**\n",
    "\n",
    "The **main difference** in problem solving lies in the backward recursion step. Instead of analytically minimizing the total cost by solving first-order conditions (as in the continuous case), we now **explicitly evaluate the cost-to-go under each possible input value** from the discrete control set. In this bang-bang setting, the input $ u_k $ is constrained to the values $-0.5$ and $+0.5$.\n",
    "\n",
    "For each time step $ k $, we proceed as follows:\n",
    "\n",
    "- First, compute the predicted next state $ \\boldsymbol{x}_{k+1} $ for each input candidate (i.e., $ u_k = -0.5 $ and $ u_k = +0.5 $).\n",
    "- Substitute each predicted state into the next-step cost-to-go function $ J_{k+1} $ to compute the corresponding total cost.\n",
    "- Compare the two resulting costs symbolically, and use the result to construct a **piecewise control policy**:  \n",
    "  choose the input that leads to the lower cost.\n",
    "- Similarly, define the new cost-to-go function $ J_k $ as the minimum of the two evaluated costs, using a piecewise expression.\n",
    "\n",
    "This approach avoids symbolic differentiation altogether and replaces it with a structured symbolic enumeration strategy, making it well-suited for systems with discrete control constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d86b1b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Step 1: implement the DP algorithm with bang-bang input**  \n",
    "\n",
    "\n",
    "The updated `setup_external()` function in the `DPController` class performs similar steps as before to compute a symbolic DP solution with discrete inputs. Most of the structure remains unchanged: symbolic variables are defined for the state and control, cost weights are converted to symbolic form, and the terminal cost is initialized at the final time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65534f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_external(self) -> None:\n",
    "\n",
    "    # start timing\n",
    "    last_time = time.time()\n",
    "\n",
    "    # Create symbolic states and inputs\n",
    "    self.x_sym = [sp.Matrix(sp.symbols(f'p_{k} v_{k}')) for k in range(self.N + 1)]\n",
    "    self.u_sym = [sp.Symbol(f'u_{k}') for k in range(self.N)]\n",
    "\n",
    "    # Convert numpy weight matrices to sympy matrices\n",
    "    self.R_sym = sp.Float(self.R)\n",
    "    self.Qf_sym = sp.Matrix(self.Qf)\n",
    "\n",
    "    # Convert numpy reference state to sympy array\n",
    "    self.x_ref_sym = sp.Matrix(self.target_state) \n",
    "\n",
    "    # Make a copy\n",
    "    J, mu = self.J_sym, self.mu_sym\n",
    "\n",
    "    # Terminal cost: J_N = (x_N - x_ref)^T Qf (x_N - x_ref)\n",
    "    err_N = self.x_sym[self.N] - self.x_ref_sym\n",
    "    J[self.N] = (err_N.T * self.Qf_sym * err_N)[0, 0]\n",
    "\n",
    "    for k in reversed(range(self.N)):\n",
    "        \n",
    "        # x_{k+1} = A x_k + B u_k\n",
    "        x_next = self.Ad * self.x_sym[k] + self.Bd * self.u_sym[k]\n",
    "\n",
    "        # Cost at step k: u_k^T R u_k + J_{k+1}(x_{k+1})\n",
    "        stage_cost = self.R_sym * self.u_sym[k]**2\n",
    "        J_kplus1_sub = J[k + 1].subs({self.x_sym[k + 1][i]: x_next[i] for i in range(2)})\n",
    "\n",
    "        total_cost = stage_cost + J_kplus1_sub\n",
    "\n",
    "        # Evaluate cost for u_k = -0.5 and u_k = 0.5\n",
    "        cost_u_lb = sp.simplify(total_cost.subs(self.u_sym[k], -0.5))\n",
    "        cost_u_ub  = sp.simplify(total_cost.subs(self.u_sym[k], 0.5))\n",
    "\n",
    "        # Try subtracting to simplify the condition\n",
    "        delta_cost = sp.simplify(cost_u_ub - cost_u_lb)\n",
    "\n",
    "        # Store optimal control policy as piecewise\n",
    "        mu_k = sp.Piecewise(\n",
    "            (-0.5, delta_cost > 0),\n",
    "            (0.5,  True)  # fallback\n",
    "        )\n",
    "        #mu_k = sp.simplify(mu_k)\n",
    "\n",
    "        # Store cost-to-go as piecewise\n",
    "        J_k = sp.Piecewise(\n",
    "            (cost_u_lb, delta_cost > 0),\n",
    "            (cost_u_ub,  True)\n",
    "        )\n",
    "        #J_k = sp.simplify(J_k)\n",
    "\n",
    "        # Store the symbolic expressions\n",
    "        mu[k] = mu_k\n",
    "        J[k] = J_k\n",
    "        \n",
    "        # Timer for each step\n",
    "        print(f\"i = {k}\")\n",
    "        print(f\"Time for single step = {time.time() - last_time:.2f} seconds\")\n",
    "        last_time = time.time()\n",
    "        \n",
    "    # Log the symbolic expressions back\n",
    "    self.J_sym = J\n",
    "    self.mu_sym = mu\n",
    "\n",
    "    if self.verbose:\n",
    "        print(f\"Dynamic Programming policy with input constraints computed.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff95fe",
   "metadata": {},
   "source": [
    "**Step 2: bind the defined cost functions and DP algorithm to the class `DPController`**  \n",
    "\n",
    "- Steps: \n",
    "\n",
    "  1) Bind the defined setup function for DP algorithm `setup_external()` to class `DPController`, it will be automatically called by constructor;\n",
    "\n",
    "  2) Specify the arguments and instantiate the class `DPController`; \n",
    "\n",
    "  3) Call function `print_solution()` to show the DP policies;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5e501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the defined DP algorithm to the corresponding class, will be automatically called by constructor\n",
    "DPController.setup = setup_external\n",
    "\n",
    "\n",
    "# Define the profile of mountain h(p)\n",
    "case_2 = 1 # 1, 2\n",
    "\n",
    "# Define the initial / target state\n",
    "initial_state_2 = np.array([-0.5, 0.0])\n",
    "target_state_2 = np.array([0.5, 0.0])\n",
    "\n",
    "# Instantiate class 'Env'\n",
    "env_2 = Env(case_2, initial_state_2, target_state_2, h, symbolic_theta)\n",
    "\n",
    "# Instantiate class 'Dynamics'\n",
    "dynamics_2 = Dynamics(env_2, state_names, input_names, setup_dynamics)\n",
    "\n",
    "\n",
    "\n",
    "# Define control frequency of controller and time length of simulation\n",
    "freq_2 = 1\n",
    "t_terminal_2 = 4 # time length of simulation\n",
    "horizon_2 = int(freq_2 * t_terminal_2)\n",
    "\n",
    "# Define weight matrix in stage and terminal cost\n",
    "Q_2 = np.diag([1, 1])\n",
    "R_2 = np.array([[0.1]]) # smaller weight because the input need to be larger to balance the effect of gravity\n",
    "Qf_2 = Q_2\n",
    "\n",
    "# Instantiate the DP controller class\n",
    "controller_dp_2 = DPController(env_2, dynamics_2, Q_2, R_2, Qf_2, freq_2, Horizon=horizon_2)\n",
    "\n",
    "# Show the symbolic expression of the policies\n",
    "controller_dp_2.print_solution()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f46006",
   "metadata": {},
   "source": [
    "**Step 3: run the simulation to see the performance of controller**  \n",
    "\n",
    "- Steps: \n",
    "\n",
    "  1) Instantiate the class `Simulator` and run function `run_simulation()` to generate the simulated state- and input-trajectory;\n",
    "\n",
    "  2) Instantiate the class `Visualizer`, run function `display_final_results()` and `display_animation()` to show the simulations;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbde0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the simulator, and then run the simulation\n",
    "simulator_dp_2 = Simulator(dynamics_2, controller_dp_2, env_2, 1/freq_2, t_terminal_2)\n",
    "simulator_dp_2.run_simulation()\n",
    "\n",
    "# Instantiate the visualizer, and display the plottings and animation\n",
    "visualizer_dp_2 = Visualizer(simulator_dp_2)\n",
    "visualizer_dp_2.display_plots()\n",
    "visualizer_dp_2.display_animation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940595b7",
   "metadata": {},
   "source": [
    "#### **Results Analysis:**\n",
    "\n",
    "From the simulation results, it can be observed that this control strategy is still capable of driving the Mountain Car system to successfully complete the task. However, from the intermediate printed outputs during the backward recursion, it becomes evident that the computation time per step grows exponentially. When the recursion depth reaches $k=4$, the time required for solving the last step already reaches approximately $40$ minutes.\n",
    "\n",
    "Moreover, from the final plot of the derived policy expressions, it is clear that the complexity of the expressions increases significantly as the recursion proceeds. This phenomenon occurs because the number of possible system evolutions grows exponentially with the number of steps. For instance, if the control input $u$ is selected from a discrete set such that $u_k \\in \\{-0.5, 0.5\\}$, and the total time horizon is discretized into $N$ steps, then the optimal policy computed at the final iteration would involve evaluating up to $2^N$ different cases.\n",
    "\n",
    "As a result, this approach inevitably encounters the curse of dimensionality, severely limiting its scalability and practical applicability to problems with longer horizons or larger state and input spaces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
